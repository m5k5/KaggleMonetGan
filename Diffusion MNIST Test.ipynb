{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import itertools as iter\n",
    "from random import shuffle\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6bbf0d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84039c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(digits.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T=1000\n",
    "beta = np.linspace(1e-4, 0.02, T)\n",
    "alpha = 1-beta\n",
    "alphaBar = [np.prod(alpha[0:i+1]) for i,el in enumerate(alpha)]\n",
    "IMAGE_SIZE = [8,8]\n",
    "tValues = np.arange(0,T)\n",
    "\n",
    "\n",
    "\n",
    "def forwardStep(x0Image,t):\n",
    "    noise = np.random.normal(0, 1, x0Image.shape)\n",
    "    noisy = np.sqrt(alphaBar[t])*x0Image + np.sqrt(1-alphaBar[t])*noise\n",
    "    return noise, noisy\n",
    "\n",
    "\n",
    "repeats=15\n",
    "def generator():\n",
    "    for imIdx in range(digits.images.shape[0]):\n",
    "        image = tf.convert_to_tensor(digits.images[imIdx])\n",
    "        image = (tf.cast(image, tf.float32) / 8.0) - 1\n",
    "        image = tf.expand_dims(image, -1)\n",
    "        x0 = image.numpy()\n",
    "        tValues = np.random.choice(T,repeats, replace=False)\n",
    "        for tValue in tValues:\n",
    "            noise, noisy = forwardStep(x0, tValue)\n",
    "            yield noisy, noise, [tValue], x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt.plot(beta, label=\"beta\")\n",
    "_ = plt.plot(np.sqrt(beta), label=r\"$\\sqrt{\\beta}$\")\n",
    "_ = plt.plot(alpha, label=r\"$\\alpha$\")\n",
    "_ = plt.plot(alphaBar, label=r\"$\\overline{\\alpha}$\")\n",
    "_ = plt.plot(np.sqrt(alphaBar), label=r\"$\\mu = \\sqrt{ \\overline{\\alpha_t} }$\")\n",
    "_ = plt.plot(np.sqrt(1-np.array(alphaBar)[np.arange(0,T)]), label=r\"$\\sigma = \\sqrt{ 1-\\overline{\\alpha_t} }$\")\n",
    "_ = plt.legend()\n",
    "_ = plt.xlabel(\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70229806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessImage(im):\n",
    "    return np.clip(im/2+0.5,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d109eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "print(test[2])\n",
    "print(test[0].shape)\n",
    "print(test[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a994b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(g)\n",
    "np.max(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c19d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(g)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(postprocessImage(test[0]), cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Image at t=\"+str(test[2][0]))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(postprocessImage(test[1]), cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86740d6b",
   "metadata": {},
   "source": [
    "## Testing of the forward and backward process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a14d9",
   "metadata": {},
   "source": [
    "Test the denoising steps all at one (what the neural network should predict gradually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd87b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDenoised = (test[0] - np.sqrt(1-alphaBar[test[2][0]])*test[1])/np.sqrt(alphaBar[test[2][0]])\n",
    "plt.imshow((testDenoised+1)/2, cmap=\"gray\")\n",
    "plt.title(\"100% denoised image\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbd178",
   "metadata": {},
   "source": [
    "Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisyImages=[]\n",
    "noises=[]\n",
    "x0=digits.images[0]/8.0-1\n",
    "for tStep in range(T):\n",
    "    noise, noisy = forwardStep(x0, tStep)\n",
    "    noisyImages.append(noisy)\n",
    "    noises.append(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "for i in range(8):\n",
    "    plt.subplot(1,8,i+1)\n",
    "    plt.imshow(postprocessImage(noisyImages[int(i*T/8)]), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"t/T = \"+str(i/8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4342a90d",
   "metadata": {},
   "source": [
    "Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4319dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [noisyImages[-1]]\n",
    "predNoises = [noises[-1]]\n",
    "\n",
    "def backwardStep(xt, t, predNoise=None, x0Pred=None):\n",
    "\n",
    "    if x0Pred is None:\n",
    "        x0Pred=(xt - np.sqrt(1-alphaBar[t])*predNoise)/np.sqrt(alphaBar[t])\n",
    "\n",
    "    if t==0:\n",
    "        sample = x0Pred\n",
    "        noise= np.zeros(xt.shape)\n",
    "    else:\n",
    "        # estimate mean\n",
    "        meanPred= x0Pred * (np.sqrt(alphaBar[t])*beta[t])/((1-alphaBar[t])*np.sqrt(alpha[t])) + xt*(alpha[t]-alphaBar[t])/((1-alphaBar[t])*np.sqrt(alpha[t]))\n",
    "\n",
    "        # compute variance\n",
    "        betaPred = np.sqrt(beta[t])\n",
    "\n",
    "        sample = meanPred + betaPred*np.random.normal(0,1,xt.shape)\n",
    "\n",
    "        noise=(sample-x0Pred*np.sqrt(alphaBar[t-1]))/np.sqrt(1-alphaBar[t-1])\n",
    "\n",
    "    return sample, noise\n",
    "\n",
    "for t in np.arange(0,T)[::-1]:\n",
    "    predNoise = predNoises[-1]\n",
    "    xt = samples[-1]\n",
    "\n",
    "    sample, noise = backwardStep(xt, t, predNoise=predNoise)\n",
    "    # sample, noise = backwardStep(xt, t, x0Pred=noisyImages[0])\n",
    "\n",
    "    samples.append(sample)\n",
    "    predNoises.append(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d647e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "for i in range(8):\n",
    "    plt.subplot(1,8,i+1)\n",
    "    plt.imshow(postprocessImage(samples[int(i*T/8)]), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"t = \"+str(int(T-i*T/8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(*IMAGE_SIZE, 1), dtype=tf.float32),\n",
    "                            tf.TensorSpec(shape=(*IMAGE_SIZE, 1), dtype=tf.float32),\n",
    "                            tf.TensorSpec(shape=(1), dtype=tf.int32),\n",
    "                            tf.TensorSpec(shape=(*IMAGE_SIZE, 1), dtype=tf.float32)))\n",
    "_ = plt.imshow(np.clip(list(dataset.take(20))[1][0].numpy()/2+0.5, 0,1), cmap=\"gray\")\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143ffe5",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a554f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createSimpleUnet(K=2):\n",
    "    inputs = tf.keras.Input(shape=(*IMAGE_SIZE, 1))\n",
    "    #256\n",
    "\n",
    "    stepInput = tf.keras.Input(shape=(1,), dtype=tf.int32)\n",
    "    # embeddedStep = tf.keras.layers.Embedding(T, 8)(stepInput)\n",
    "    # stepMap = tf.repeat(embeddedStep, 8, axis=0)\n",
    "    # stepMap = tf.reshape(stepMap, (-1,*IMAGE_SIZE, 1))\n",
    "\n",
    "    # concatInput = tf.keras.layers.Concatenate()([inputs, stepMap])\n",
    "\n",
    "    xDown1In = tf.keras.layers.Conv2D(K*8, 3, padding=\"same\", activation=\"relu\" )(inputs)\n",
    "    xDown1 = tf.keras.layers.Conv2D(K*16, 3, padding=\"same\", strides=2, activation=\"relu\")(xDown1In)\n",
    "    xDown1 = tf.keras.layers.Conv2D(K*16, 3, padding=\"same\", activation=\"relu\")(xDown1)\n",
    "    #4x4\n",
    "    \n",
    "    xDown2 = tf.keras.layers.Conv2D(K*16, 3, padding=\"same\", activation=\"relu\" )(xDown1)\n",
    "    xDown2 = tf.keras.layers.Conv2D(K*32, 3, padding=\"same\", strides=2, activation=\"relu\")(xDown2)\n",
    "    xDown2 = tf.keras.layers.Conv2D(K*32, 3, padding=\"same\", activation=\"relu\" )(xDown2)\n",
    "    #2x2\n",
    "\n",
    "\n",
    "    xCenter = tf.keras.layers.Conv2D(K*64, 3, padding=\"same\" )(xDown2)\n",
    "\n",
    "    # stepMap16 = tf.keras.layers.Conv2D(3, 3, strides=4, padding=\"same\")(stepMap)\n",
    "    # concatCenter = tf.keras.layers.Concatenate()([xCenter, stepMap16])\n",
    "\n",
    "    xCenter = tf.keras.layers.Conv2D(K*64, 3, dilation_rate=2, padding=\"same\", activation=\"relu\")(xCenter)\n",
    "    # 2x2\n",
    "\n",
    "\n",
    "\n",
    "    xUp2 = tf.keras.layers.Conv2D(K*32, 3, padding=\"same\", activation=\"relu\")(xCenter)\n",
    "    xDown2Concat = tf.keras.layers.Conv2D(K*32, 1, padding=\"same\")(xDown2)\n",
    "    xConcat2 = tf.keras.layers.Concatenate()([xUp2, xDown2Concat])\n",
    "    xUp2 = tf.keras.layers.Conv2D(K*32, 3, padding=\"same\", activation=\"relu\" )(xConcat2)\n",
    "    xUp2 = tf.keras.layers.Conv2DTranspose(K*16, 3, padding=\"same\", strides=2, activation=\"relu\")(xUp2)\n",
    "    xUp2 = tf.keras.layers.Conv2D(K*16, 3, padding=\"same\", activation=\"relu\" )(xUp2)\n",
    "    #4x4\n",
    "\n",
    "    xUp1 = tf.keras.layers.Conv2D(K*16, 3, padding=\"same\", activation=\"relu\")(xUp2)\n",
    "    xDown1Concat = tf.keras.layers.Conv2D(K*16, 1, padding=\"same\")(xDown1)\n",
    "    xConcat1 = tf.keras.layers.Concatenate()([xUp1, xDown1Concat])\n",
    "    xUp1 = tf.keras.layers.Conv2D(K*16, 3, padding=\"same\", activation=\"relu\" )(xConcat1)\n",
    "    xUp1 = tf.keras.layers.Conv2DTranspose(K*8, 3, padding=\"same\", strides=2, activation=\"relu\")(xUp1)\n",
    "    xUp1 = tf.keras.layers.Conv2D(K*8, 3, padding=\"same\", activation=\"relu\" )(xUp1)\n",
    "    #8x8\n",
    "\n",
    "    xDown1InConcat = tf.keras.layers.Conv2D(K*8, 1, padding=\"same\")(xDown1In)\n",
    "    xConcat = tf.keras.layers.Concatenate()([xUp1, xDown1InConcat])\n",
    "    x = tf.keras.layers.Conv2D(K*8, 3, padding=\"same\", activation=\"relu\" )(xConcat)\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(K*8, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "    outputs=tf.keras.layers.Conv2D(1, 1, padding=\"same\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs,stepInput], outputs=outputs, name=\"SimpleUnetMNIST_K{}\".format(K))\n",
    "\n",
    "\n",
    "model = createSimpleUnet(K=16)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "dot_img_file = './'+model.name +'.png'\n",
    "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98752d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2=0\n",
    "\n",
    "def downscaleBlock(xIn, chBefore, chAfter, filtersize):\n",
    "    x = tf.keras.layers.BatchNormalization()(xIn)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    # xRes = tf.keras.layers.AveragePooling2D((3,3), strides=2, padding=\"same\")(x)\n",
    "    xRes = tf.keras.layers.Conv2D(chAfter, 1, strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(chBefore, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    # x = tf.keras.layers.AveragePooling2D((3,3), strides=2, padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Conv2D(chAfter, filtersize, strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(chAfter, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    added = tf.math.add(x, xRes)\n",
    "    \n",
    "    return added\n",
    "\n",
    "\n",
    "def upscaleBlock(xIn, chBefore, chAfter, filtersize):\n",
    "    x = tf.keras.layers.BatchNormalization()(xIn)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    xRes = tf.keras.layers.UpSampling2D(size=(2, 2))(x)\n",
    "    # xRes = tf.keras.layers.Conv2DTranspose(chAfter, filtersize, strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(xIn)\n",
    "    xRes = tf.keras.layers.Conv2D(chAfter, 1, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(xRes)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(chBefore, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(xIn)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.UpSampling2D(size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(chAfter, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "    # x = tf.keras.layers.Conv2DTranspose(chAfter, filtersize, strides=2, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(chAfter, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    added = tf.math.add(x, xRes)\n",
    "\n",
    "    return added\n",
    "\n",
    "\n",
    "def nonLocalBlock(xIn, ch, filtersize=1):\n",
    "    theta = tf.keras.layers.Conv2D(ch, filtersize, padding=\"same\")(xIn)\n",
    "    phi = tf.keras.layers.Conv2D(ch, filtersize, padding=\"same\")(xIn)\n",
    "    g = tf.keras.layers.Conv2D(ch, filtersize, padding=\"same\")(xIn)\n",
    "    out = tf.keras.layers.Attention()([theta, phi, g])\n",
    "    return tf.math.add(xIn, out)\n",
    "\n",
    "\n",
    "def centerBlock(xIn, stepMap, ch, filtersize):\n",
    "    x = tf.keras.layers.BatchNormalization()(xIn)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(ch, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    stepMap16 = tf.keras.layers.Conv2D(3, filtersize, strides=4, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(stepMap)\n",
    "    concatCenter = tf.keras.layers.Concatenate()([x, stepMap16])\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(concatCenter)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(ch, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    x = nonLocalBlock(x, ch)\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(ch, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def createUnet(K=2):\n",
    "    inputs = tf.keras.Input(shape=(*IMAGE_SIZE, 1))\n",
    "    #256\n",
    "\n",
    "    stepInput = tf.keras.Input(shape=(1,), dtype=tf.int32)\n",
    "    embeddedStep = tf.keras.layers.Embedding(T, 8)(stepInput)\n",
    "    stepMap = tf.repeat(embeddedStep, 8, axis=0)\n",
    "    stepMap = tf.reshape(stepMap, (-1,*IMAGE_SIZE, 1))\n",
    "\n",
    "    concatInput = tf.keras.layers.Concatenate()([inputs, stepMap])\n",
    "\n",
    "    xDown2 = tf.keras.layers.Conv2D(K*2, 3, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(concatInput)\n",
    "    \n",
    "    xDown4 = downscaleBlock(xDown2, K*2, K*4, 3)\n",
    "    #128\n",
    "\n",
    "    xDown8 = downscaleBlock(xDown4, K*4, K*8, 3)\n",
    "    #64\n",
    "\n",
    "\n",
    "    xCenter = centerBlock(xDown8, stepMap, K*8, 3)\n",
    "    #16x16\n",
    "\n",
    "\n",
    "    xUp4 = upscaleBlock(xCenter, K*8, K*4, 3)\n",
    "    #128\n",
    "    xConcat4 = tf.keras.layers.Concatenate()([xDown4, xUp4])\n",
    "    xUp4 = tf.keras.layers.BatchNormalization()(xConcat4)\n",
    "    xUp4 = tf.keras.layers.LeakyReLU()(xUp4)\n",
    "    xUp4=tf.keras.layers.Conv2D(K*4, 3, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(xUp4)\n",
    "\n",
    "    xUp2 = upscaleBlock(xUp4, K*4, K*2, 3)\n",
    "    #256\n",
    "    xConcat2 = tf.keras.layers.Concatenate()([xDown2, xUp2])\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(xConcat2)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(K*2, 3, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(K*2, 3, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=L2))(x)\n",
    "\n",
    "    outputs=tf.keras.layers.Conv2D(1, 1, padding=\"same\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs,stepInput], outputs=outputs, name=\"unet_MNIST_T{}_K{}\".format(T,K))\n",
    "\n",
    "\n",
    "# model = createUnet(K=4)\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# dot_img_file = './'+model.name +'.png'\n",
    "# tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afa90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadExistingModel=False\n",
    "\n",
    "if loadExistingModel:\n",
    "    model = tf.keras.models.load_model(os.path.join(DATA_PATH, \"diffusionModelMNIST_epoch_0\"))\n",
    "    startEpoch=1\n",
    "else:\n",
    "    startEpoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1533cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveImages(model, epoch, step, summary_writer=None, maxStep=0):\n",
    "  initInput = tf.random.normal((3, *IMAGE_SIZE, 1), dtype=tf.float32)\n",
    "  samples = [initInput]\n",
    "\n",
    "  for t in np.arange(0,T)[::-1]:\n",
    "      pred = model((samples[-1], tf.constant([t, t, t])), training=False)\n",
    "      xt = samples[-1]\n",
    "      \n",
    "      # sample, noise = backwardStep(xt, t, x0Pred=predX0)\n",
    "      sample, noise = backwardStep(xt, t, predNoise=pred)\n",
    "\n",
    "      samples.append(sample)\n",
    "\n",
    "  _ = plt.figure(figsize=(12,8))\n",
    "\n",
    "  sampleIdx = np.linspace(0, T, 5)\n",
    "\n",
    "  for j in range(3):\n",
    "    for i in range(5):\n",
    "        _ = plt.subplot(3, 5, j*5+i+1)\n",
    "        plt.imshow(postprocessImage(samples[int(sampleIdx[i])])[j,:,:,:],cmap='gray')\n",
    "        if summary_writer is not None:\n",
    "           with summary_writer.as_default():\n",
    "              tf.summary.image(\"Training data\", postprocessImage(samples[int(sampleIdx[-1])]), step=maxStep*epoch+step)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Step {}\".format(T-int(sampleIdx[i])))\n",
    "\n",
    "  plt.savefig(os.path.join(DATA_PATH,\"trainImagesDiffusionMNIST\", 'epoch_{:04d}_step_{:04d}.png'.format(epoch, step)))\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b554933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSESSIMLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha):\n",
    "        super().__init__(name=\"MSE_SSIM_Loss\")\n",
    "        assert(alpha<1.0)\n",
    "        self.alpha = tf.constant(alpha)\n",
    "        \n",
    "    def call(self, yTrue, yPred):\n",
    "        mse =  tf.math.reduce_mean(tf.math.square(yPred - yTrue))\n",
    "        ssim = tf.image.ssim(tf.clip_by_value(yPred,-1,1)/2+0.5, tf.clip_by_value(yTrue,-1,1)/2+0.5, max_val=1.0)\n",
    "        ssimLoss =  1-tf.math.reduce_mean(ssim, axis=-1)\n",
    "        return (1-self.alpha)*mse + self.alpha*ssimLoss\n",
    "\n",
    "testLoss = MSESSIMLoss(0.2)\n",
    "testLoss(tf.ones([1,20,20,3]), tf.ones([1,20,20,3])*0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE=64\n",
    "LOG_INTERVAL=5\n",
    "SAVE_IMAGE_INTERVAL=10\n",
    "epochs = 201\n",
    "saveModel=False\n",
    "\n",
    "\n",
    "\n",
    "log_dir = \"./logs/\"+model.name+\"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
    "                                                      write_graph=True, update_freq=5)\n",
    "\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Instantiate an optimizer .\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=5e-4)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "# lossFn = tf.keras.losses.MeanAbsoluteError()\n",
    "lossFn = tf.keras.losses.MeanSquaredError()\n",
    "# lossFn = MSESSIMLoss(0.1)\n",
    "\n",
    "mseMetric = tf.keras.metrics.MeanSquaredError()\n",
    "\n",
    "\n",
    "# batchedDataset = datasetMonet.batch(BATCH_SIZE, drop_remainder=False)\n",
    "datasetShuffled = dataset.shuffle(1000)\n",
    "batchedDataset = datasetShuffled.batch(BATCH_SIZE, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def trainStep(noisyImage, noise, t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted = model((noisyImage, t), training=True) \n",
    "\n",
    "        loss = lossFn(predicted, noise)\n",
    "\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights)) \n",
    "\n",
    "    mseMetric.update_state(predicted,noise)\n",
    "\n",
    "    return loss, predicted\n",
    "\n",
    "\n",
    "\n",
    "maxStep=digits.images.shape[0]*repeats//BATCH_SIZE\n",
    "\n",
    "\n",
    "for epoch in np.arange(startEpoch, startEpoch+epochs, 1):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (noisyImage, noise, t, x0) in enumerate(batchedDataset):\n",
    "        loss, predictedImage = trainStep(noisyImage, noise, t)\n",
    "\n",
    "        # Log \n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            template = 'Epoch {}/Step {}, Loss: {:.4f}'\n",
    "            print(template.format(epoch, step, mseMetric.result().numpy()))\n",
    "            \n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', mseMetric.result().numpy(), step=maxStep*epoch+step)\n",
    "                summary_writer.flush()\n",
    "        \n",
    "    if epoch % SAVE_IMAGE_INTERVAL==0:\n",
    "        saveImages(model, epoch, step, summary_writer, maxStep)\n",
    "\n",
    "    maxStep=step\n",
    "\n",
    "    mseMetric.reset_state()\n",
    "\n",
    "    if saveModel:\n",
    "      model.save(os.path.join(DATA_PATH, model.name+\"epoch_{}\".format(epoch)))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fdecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initInput = tf.random.normal((2, *IMAGE_SIZE, 3), dtype=tf.float32)\n",
    "samples = [initInput]\n",
    "\n",
    "for t in np.arange(0,T)[::-1]:\n",
    "    predNoise = model((samples[-1], tf.constant([t,t])))\n",
    "    xt = samples[-1]\n",
    "    \n",
    "    sample, noise = backwardStep(xt, predNoise, t)\n",
    "\n",
    "    samples.append(sample)\n",
    "\n",
    "_ = plt.figure(figsize=(12,5))\n",
    "\n",
    "sampleIdx = np.linspace(0, T, 5)\n",
    "\n",
    "for j in range(2):\n",
    "    for i in range(5):\n",
    "        _ = plt.subplot(2,5,j*5+i+1)\n",
    "        plt.imshow(np.clip((samples[int(sampleIdx[i])].numpy()[j,:,:,:]+1)/2, 0, 1))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Step {}\".format(T-int(sampleIdx[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage=tf.expand_dims(list(dataset.take(50))[34][0],0)\n",
    "testT=tf.expand_dims(list(dataset.take(50))[34][2],0)\n",
    "testNoise=tf.expand_dims(list(dataset.take(50))[34][1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d60b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predNoise = model((testImage, testT))\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow((predNoise.numpy()[0,:,:,:]+1)/2)\n",
    "plt.title(\"Predicted Noise\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Real Noise\")\n",
    "plt.imshow((testNoise.numpy()[0,:,:,:]+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94676b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "testTNum = testT.numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84490c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = (testImage - (1-alpha[testTNum])/np.sqrt(1-alphaBar[testTNum])*predNoise)/np.sqrt(alpha[testTNum])\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow((testImage.numpy()[0,:,:,:]+1)/2)\n",
    "plt.title(\"Original Image\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Denoised Image by 1 step\")\n",
    "plt.imshow((denoised.numpy()[0,:,:,:]+1)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928bcfc1",
   "metadata": {},
   "source": [
    "## Hparam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "HP_K = hp.HParam('K', hp.Discrete([2]))\n",
    "HP_LR = hp.HParam('lr', hp.Discrete([1e-4, 5e-4, 1e-3, 5e-3] ))\n",
    "\n",
    "METRIC_HP = 'loss'\n",
    "\n",
    "with tf.summary.create_file_writer(os.path.join(DATA_PATH,'logs/hparam_tuning3')).as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_K, HP_LR],\n",
    "    metrics=[hp.Metric(METRIC_HP, display_name='MSE')],\n",
    "  )\n",
    "\n",
    "def trainTestModel(hparams):\n",
    "  model = createSimpleUnet(K=hparams[HP_K])\n",
    "\n",
    "    \n",
    "  BATCH_SIZE=64\n",
    "  epochs = 10\n",
    "\n",
    "\n",
    "  optimizer = tf.keras.optimizers.AdamW(learning_rate=hparams[HP_LR])\n",
    "  lossFn = tf.keras.losses.MeanSquaredError()\n",
    "  mseMetric = tf.keras.metrics.MeanSquaredError()\n",
    "\n",
    "  # batchedDataset = datasetMonet.batch(BATCH_SIZE, drop_remainder=False)\n",
    "  datasetShuffled = dataset.shuffle(1000)\n",
    "  batchedDataset = datasetShuffled.batch(BATCH_SIZE, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "  @tf.function()\n",
    "  def trainStep(noisyImage, noise, t):\n",
    "      with tf.GradientTape() as tape:\n",
    "          predicted = model((noisyImage, t), training=True) \n",
    "\n",
    "          loss = lossFn(predicted, noise)\n",
    "\n",
    "\n",
    "      grads = tape.gradient(loss, model.trainable_weights)\n",
    "\n",
    "      optimizer.apply_gradients(zip(grads, model.trainable_weights)) \n",
    "\n",
    "      mseMetric.update_state(predicted,noise)\n",
    "\n",
    "      return loss, predicted\n",
    "\n",
    "\n",
    "\n",
    "  for epoch in np.arange(0, epochs, 1):\n",
    "      print(\"start epoch \", epoch)\n",
    "\n",
    "      # Iterate over the batches of the dataset.\n",
    "      for step, (noisyImage, noise, t, x0) in enumerate(batchedDataset):\n",
    "          loss, predictedImage = trainStep(noisyImage, noise, t)\n",
    "\n",
    "\n",
    "      if not epoch == epochs-1:\n",
    "        mseMetric.reset_state()\n",
    "\n",
    "  return mseMetric.result().numpy()\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    loss = trainTestModel(hparams)\n",
    "    tf.summary.scalar(METRIC_HP, loss, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be825a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "\n",
    "for K in HP_K.domain.values:\n",
    "  for lr in HP_LR.domain.values:\n",
    "    hparams = {\n",
    "        HP_K: K,\n",
    "        HP_LR: lr,\n",
    "    }\n",
    "    run_name = \"run-%d\" % session_num\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run('logs/hparam_tuning3/' + run_name, hparams)\n",
    "    session_num += 1\n",
    "\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
