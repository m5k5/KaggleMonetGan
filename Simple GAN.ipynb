{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import itertools as iter\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "\n",
    "\n",
    "DATA_PATH = os.getenv('DATA_PATH')\n",
    "print(DATA_PATH)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3544f8a",
   "metadata": {},
   "source": [
    "## Reading tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filpaths=[]\n",
    "for root,dirs,files in os.walk(os.path.join(DATA_PATH, \"monet_tfrec\")):\n",
    "    for f in files:\n",
    "       filpaths.append(os.path.join(root,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76779a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [256, 256]\n",
    "\n",
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40646480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetMonet = load_dataset(filpaths, labeled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6bbf0d",
   "metadata": {},
   "source": [
    "## Larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bfc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles=[]\n",
    "for root, dirs, files in os.walk(os.path.join(DATA_PATH, \"processed\")):\n",
    "    for f in files:\n",
    "        allFiles.append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    for i,file in enumerate(allFiles):\n",
    "        image = tf.io.read_file(file)\n",
    "        image = tf.io.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.random_brightness(image, 0.1)\n",
    "        image = tf.image.random_contrast(image, 0.95, 1.05)\n",
    "        image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "        yield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d109eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = generator()\n",
    "test = next(g)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c19d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(g)\n",
    "plt.imshow(((test.numpy()+1)/2))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(tf.TensorSpec(shape=(*IMAGE_SIZE, 3), dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143ffe5",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a554f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98752d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def upscaleBlock(xIn, channelsBefore, channelsAfter, filtersize):\n",
    "    xRes = tf.keras.layers.UpSampling2D(size=(2, 2))(xIn)\n",
    "    xRes = tf.keras.layers.Conv2D(channelsAfter, 1, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(xRes)\n",
    "\n",
    "    # x = tf.keras.layers.Conv2D(channelsBefore, filtersize, padding=\"same\")(xIn)\n",
    "    x = tf.keras.layers.BatchNormalization()(xIn)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    x = tf.keras.layers.UpSampling2D(size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(channelsAfter, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(channelsAfter, filtersize, padding=\"same\")(x)\n",
    "\n",
    "    return tf.math.add(x, xRes)\n",
    "\n",
    "\n",
    "def nonLocalBlock(xIn, ch, filtersize=1):\n",
    "    theta = tf.keras.layers.Conv2D(ch, filtersize, padding=\"same\")(xIn)\n",
    "    phi = tf.keras.layers.Conv2D(ch, filtersize, padding=\"same\")(xIn)\n",
    "    g = tf.keras.layers.Conv2D(ch, filtersize, padding=\"same\")(xIn)\n",
    "    out = tf.keras.layers.Attention()([theta, phi, g])\n",
    "    return tf.math.add(xIn, out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def createGenerator():\n",
    "    inputs = tf.keras.Input(shape=(1024,))\n",
    "    # x=layers.Embedding(VOCAB_SIZE, EMBED_DIM, name=\"embedding\")(inputs)\n",
    "\n",
    "    x=tf.keras.layers.Dense(4*4*64, kernel_regularizer=\"l2\")(inputs)\n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    x=tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x=tf.keras.layers.Reshape((4,4,64))(x)\n",
    "\n",
    "    x = upscaleBlock(x, 64, 32, 3)\n",
    "\n",
    "    x = upscaleBlock(x, 32, 16, 3)\n",
    "\n",
    "    x = upscaleBlock(x, 16, 8, 3)\n",
    "\n",
    "    x = upscaleBlock(x, 8, 8, 3)\n",
    "\n",
    "    x = nonLocalBlock(x, 8)\n",
    "\n",
    "    x = upscaleBlock(x, 8, 4, 3)\n",
    "\n",
    "    x = upscaleBlock(x, 4, 2, 3)\n",
    "\n",
    "\n",
    "    x=tf.keras.layers.BatchNormalization()(x)\n",
    "    x=tf.keras.layers.LeakyReLU()(x)\n",
    "    \n",
    "    x=tf.keras.layers.Conv2D(3, 3, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(x)\n",
    "    outputs = tf.keras.activations.tanh(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"generator\")\n",
    "\n",
    "generator = createGenerator()\n",
    "\n",
    "generator.summary()\n",
    "\n",
    "dot_img_file = './'+generator.name +'.png'\n",
    "tf.keras.utils.plot_model(generator, to_file=dot_img_file, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d56de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscaleBlock(xIn, channelsBefore, channelsAfter, filtersize):\n",
    "    xRes = tf.keras.layers.Conv2D(channelsAfter, 1, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(xIn)\n",
    "    xRes = tf.keras.layers.AveragePooling2D((3,3), strides=2)(xRes)\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(xIn)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(channelsBefore, filtersize, padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(x)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(channelsAfter, filtersize, strides=2, kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(x)\n",
    "    \n",
    "    return tf.math.add(x, xRes)\n",
    "\n",
    "\n",
    "def createDiscriminator():\n",
    "    inputs = tf.keras.Input(shape=(*IMAGE_SIZE, 3))\n",
    "\n",
    "\n",
    "    x = downscaleBlock(inputs, 2, 4, 3)\n",
    "\n",
    "    x = downscaleBlock(x, 4, 8, 3)\n",
    "    \n",
    "    x = downscaleBlock(x, 8, 16, 3)\n",
    "    \n",
    "    x = downscaleBlock(x, 16, 32, 3)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(32,3, kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(32, kernel_regularizer=tf.keras.regularizers.L2(l2=0.05))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(32, kernel_regularizer=tf.keras.regularizers.L2(l2=0.01))(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    # outputs=layers.Dense(1, activation=tf.keras.activations.sigmoid)(x)\n",
    "    outputs=layers.Dense(1,)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"Discriminator\")\n",
    "\n",
    "discriminator = createDiscriminator()\n",
    "\n",
    "discriminator.summary()\n",
    "\n",
    "dot_img_file = './'+discriminator.name +'.png'\n",
    "tf.keras.utils.plot_model(discriminator, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afa90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadExistingModel=False\n",
    "\n",
    "if loadExistingModel:\n",
    "    generator = tf.keras.models.load_model(os.path.join(DATA_PATH, \"generator_epoch_190\"))\n",
    "    discriminator = tf.keras.models.load_model(os.path.join(DATA_PATH, \"discriminator_epoch_190\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e1533cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveImages(model, epoch):\n",
    "  testInput = tf.random.uniform((9, 1024))\n",
    "  predictions = model(testInput, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(np.rint(predictions[i, :, :, :] * 127.5 + 127.5).astype(int))\n",
    "    plt.axis('off')\n",
    "\n",
    "  plt.savefig(os.path.join(DATA_PATH,\"trainImages\", 'epoch_{:04d}.png'.format(epoch)))\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9113c4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Epoch 0/Step 0, Loss Generator: 0.8751, Loss Discriminator: 0.0929, Accuracy Dis: 1.0000\n",
      "Epoch 0/Step 5, Loss Generator: 0.8689, Loss Discriminator: 0.0797, Accuracy Dis: 0.9883\n",
      "Epoch 0/Step 10, Loss Generator: 0.8830, Loss Discriminator: 0.0656, Accuracy Dis: 0.9893\n",
      "Epoch 0/Step 15, Loss Generator: 0.9717, Loss Discriminator: 0.0557, Accuracy Dis: 0.9863\n",
      "Epoch 0/Step 20, Loss Generator: 0.9486, Loss Discriminator: 0.0613, Accuracy Dis: 0.9870\n",
      "Epoch 0/Step 25, Loss Generator: 0.8916, Loss Discriminator: 0.0656, Accuracy Dis: 0.9886\n",
      "Saving images\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 1\n",
      "Epoch 1/Step 0, Loss Generator: 0.9057, Loss Discriminator: 0.0504, Accuracy Dis: 0.9844\n",
      "Epoch 1/Step 5, Loss Generator: 0.9590, Loss Discriminator: 0.0332, Accuracy Dis: 0.9909\n",
      "Epoch 1/Step 10, Loss Generator: 0.9696, Loss Discriminator: 0.0484, Accuracy Dis: 0.9936\n",
      "Epoch 1/Step 15, Loss Generator: 0.9361, Loss Discriminator: 0.0446, Accuracy Dis: 0.9927\n",
      "Epoch 1/Step 20, Loss Generator: 1.0156, Loss Discriminator: 0.0412, Accuracy Dis: 0.9944\n",
      "Epoch 1/Step 25, Loss Generator: 0.9459, Loss Discriminator: 0.0405, Accuracy Dis: 0.9946\n",
      "Saving images\n",
      "\n",
      "Start of epoch 2\n",
      "Epoch 2/Step 0, Loss Generator: 0.9793, Loss Discriminator: 0.0618, Accuracy Dis: 0.9922\n",
      "Epoch 2/Step 5, Loss Generator: 0.9121, Loss Discriminator: 0.0393, Accuracy Dis: 0.9948\n",
      "Epoch 2/Step 10, Loss Generator: 0.9053, Loss Discriminator: 0.0544, Accuracy Dis: 0.9950\n",
      "Epoch 2/Step 15, Loss Generator: 0.9134, Loss Discriminator: 0.0487, Accuracy Dis: 0.9946\n",
      "Epoch 2/Step 20, Loss Generator: 0.9249, Loss Discriminator: 0.0493, Accuracy Dis: 0.9955\n",
      "Epoch 2/Step 25, Loss Generator: 0.8607, Loss Discriminator: 0.0569, Accuracy Dis: 0.9961\n",
      "Saving images\n",
      "\n",
      "Start of epoch 3\n",
      "Epoch 3/Step 0, Loss Generator: 0.8940, Loss Discriminator: 0.0519, Accuracy Dis: 1.0000\n",
      "Epoch 3/Step 5, Loss Generator: 0.8433, Loss Discriminator: 0.0431, Accuracy Dis: 0.9961\n",
      "Epoch 3/Step 10, Loss Generator: 0.8712, Loss Discriminator: 0.0545, Accuracy Dis: 0.9979\n",
      "Epoch 3/Step 15, Loss Generator: 0.7972, Loss Discriminator: 0.0669, Accuracy Dis: 0.9956\n",
      "Epoch 3/Step 20, Loss Generator: 0.7885, Loss Discriminator: 0.0478, Accuracy Dis: 0.9955\n",
      "Epoch 3/Step 25, Loss Generator: 0.7919, Loss Discriminator: 0.0692, Accuracy Dis: 0.9961\n",
      "Saving images\n",
      "\n",
      "Start of epoch 4\n",
      "Epoch 4/Step 0, Loss Generator: 0.7863, Loss Discriminator: 0.0622, Accuracy Dis: 1.0000\n",
      "Epoch 4/Step 5, Loss Generator: 0.9620, Loss Discriminator: 0.0491, Accuracy Dis: 0.9987\n",
      "Epoch 4/Step 10, Loss Generator: 1.0186, Loss Discriminator: 0.0790, Accuracy Dis: 0.9964\n",
      "Epoch 4/Step 15, Loss Generator: 0.9431, Loss Discriminator: 0.0363, Accuracy Dis: 0.9956\n",
      "Epoch 4/Step 20, Loss Generator: 0.9253, Loss Discriminator: 0.0429, Accuracy Dis: 0.9963\n",
      "Epoch 4/Step 25, Loss Generator: 0.9160, Loss Discriminator: 0.0376, Accuracy Dis: 0.9967\n",
      "Decrease disc training frequency to every 2 steps\n",
      "Saving images\n",
      "\n",
      "Start of epoch 5\n",
      "Epoch 5/Step 0, Loss Generator: 0.9583, Loss Discriminator: 0.0391, Accuracy Dis: 1.0000\n",
      "Epoch 5/Step 5, Loss Generator: 0.9580, Loss Discriminator: 0.0343, Accuracy Dis: 0.9909\n",
      "Epoch 5/Step 10, Loss Generator: 0.8992, Loss Discriminator: 0.0491, Accuracy Dis: 0.9915\n",
      "Epoch 5/Step 15, Loss Generator: 1.0124, Loss Discriminator: 0.0579, Accuracy Dis: 0.9932\n",
      "Epoch 5/Step 20, Loss Generator: 0.8921, Loss Discriminator: 0.0564, Accuracy Dis: 0.9944\n",
      "Epoch 5/Step 25, Loss Generator: 0.8911, Loss Discriminator: 0.0432, Accuracy Dis: 0.9952\n",
      "Decrease disc training frequency to every 3 steps\n",
      "Saving images\n",
      "\n",
      "Start of epoch 6\n",
      "Epoch 6/Step 0, Loss Generator: 0.9251, Loss Discriminator: 0.0424, Accuracy Dis: 1.0000\n",
      "Epoch 6/Step 5, Loss Generator: 0.9796, Loss Discriminator: 0.0504, Accuracy Dis: 0.9961\n",
      "Epoch 6/Step 10, Loss Generator: 0.9488, Loss Discriminator: 0.0395, Accuracy Dis: 0.9964\n",
      "Epoch 6/Step 15, Loss Generator: 0.9481, Loss Discriminator: 0.0270, Accuracy Dis: 0.9971\n",
      "Epoch 6/Step 20, Loss Generator: 0.9384, Loss Discriminator: 0.0363, Accuracy Dis: 0.9970\n",
      "Epoch 6/Step 25, Loss Generator: 0.9087, Loss Discriminator: 0.0431, Accuracy Dis: 0.9973\n",
      "Decrease disc training frequency to every 4 steps\n",
      "Saving images\n",
      "\n",
      "Start of epoch 7\n",
      "Epoch 7/Step 0, Loss Generator: 0.9713, Loss Discriminator: 0.0287, Accuracy Dis: 1.0000\n",
      "Epoch 7/Step 5, Loss Generator: 0.8972, Loss Discriminator: 0.0386, Accuracy Dis: 0.9987\n",
      "Epoch 7/Step 10, Loss Generator: 0.8936, Loss Discriminator: 0.0427, Accuracy Dis: 0.9972\n",
      "Epoch 7/Step 15, Loss Generator: 0.9187, Loss Discriminator: 0.0278, Accuracy Dis: 0.9976\n",
      "Epoch 7/Step 20, Loss Generator: 0.8829, Loss Discriminator: 0.0343, Accuracy Dis: 0.9970\n",
      "Epoch 7/Step 25, Loss Generator: 0.9644, Loss Discriminator: 0.0485, Accuracy Dis: 0.9967\n",
      "Decrease disc training frequency to every 5 steps\n",
      "Saving images\n",
      "\n",
      "Start of epoch 8\n",
      "Epoch 8/Step 0, Loss Generator: 0.9502, Loss Discriminator: 0.0495, Accuracy Dis: 0.9766\n",
      "Epoch 8/Step 5, Loss Generator: 0.9114, Loss Discriminator: 0.0416, Accuracy Dis: 0.9935\n",
      "Epoch 8/Step 10, Loss Generator: 0.8877, Loss Discriminator: 0.0377, Accuracy Dis: 0.9950\n",
      "Epoch 8/Step 15, Loss Generator: 0.8954, Loss Discriminator: 0.0259, Accuracy Dis: 0.9946\n",
      "Epoch 8/Step 20, Loss Generator: 0.8661, Loss Discriminator: 0.0394, Accuracy Dis: 0.9952\n",
      "Epoch 8/Step 25, Loss Generator: 0.9281, Loss Discriminator: 0.0357, Accuracy Dis: 0.9955\n",
      "Decrease disc training frequency to every 6 steps\n",
      "Saving images\n",
      "\n",
      "Start of epoch 9\n",
      "Epoch 9/Step 0, Loss Generator: 0.8849, Loss Discriminator: 0.0335, Accuracy Dis: 1.0000\n",
      "Epoch 9/Step 5, Loss Generator: 0.8381, Loss Discriminator: 0.0333, Accuracy Dis: 0.9974\n",
      "Epoch 9/Step 10, Loss Generator: 0.9408, Loss Discriminator: 0.0362, Accuracy Dis: 0.9979\n",
      "Epoch 9/Step 15, Loss Generator: 0.9153, Loss Discriminator: 0.0363, Accuracy Dis: 0.9985\n",
      "Epoch 9/Step 20, Loss Generator: 0.9658, Loss Discriminator: 0.0354, Accuracy Dis: 0.9978\n",
      "Epoch 9/Step 25, Loss Generator: 0.8909, Loss Discriminator: 0.0476, Accuracy Dis: 0.9976\n",
      "Decrease disc training frequency to every 7 steps\n",
      "Saving images\n",
      "\n",
      "Start of epoch 10\n",
      "Epoch 10/Step 0, Loss Generator: 0.9070, Loss Discriminator: 0.0321, Accuracy Dis: 1.0000\n",
      "Epoch 10/Step 5, Loss Generator: 0.9147, Loss Discriminator: 0.0418, Accuracy Dis: 1.0000\n",
      "Epoch 10/Step 10, Loss Generator: 0.9377, Loss Discriminator: 0.0322, Accuracy Dis: 0.9979\n",
      "Epoch 10/Step 15, Loss Generator: 0.9134, Loss Discriminator: 0.0386, Accuracy Dis: 0.9956\n",
      "Epoch 10/Step 20, Loss Generator: 0.8752, Loss Discriminator: 0.0410, Accuracy Dis: 0.9963\n",
      "Epoch 10/Step 25, Loss Generator: 0.8636, Loss Discriminator: 0.0406, Accuracy Dis: 0.9964\n",
      "Decrease disc training frequency to every 8 steps\n",
      "Saving images\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 11\n",
      "Epoch 11/Step 0, Loss Generator: 0.9691, Loss Discriminator: 0.0359, Accuracy Dis: 1.0000\n",
      "Epoch 11/Step 5, Loss Generator: 0.9028, Loss Discriminator: 0.0304, Accuracy Dis: 0.9987\n",
      "Epoch 11/Step 10, Loss Generator: 0.9184, Loss Discriminator: 0.0236, Accuracy Dis: 0.9972\n",
      "Epoch 11/Step 15, Loss Generator: 0.9082, Loss Discriminator: 0.0259, Accuracy Dis: 0.9976\n",
      "Epoch 11/Step 20, Loss Generator: 0.8813, Loss Discriminator: 0.0297, Accuracy Dis: 0.9981\n",
      "Epoch 11/Step 25, Loss Generator: 0.8885, Loss Discriminator: 0.0503, Accuracy Dis: 0.9979\n",
      "Decrease disc training frequency to every 9 steps\n",
      "Saving images\n",
      "\n",
      "Start of epoch 12\n",
      "Epoch 12/Step 0, Loss Generator: 0.9564, Loss Discriminator: 0.0400, Accuracy Dis: 0.9922\n",
      "Epoch 12/Step 5, Loss Generator: 0.8167, Loss Discriminator: 0.0405, Accuracy Dis: 0.9961\n",
      "Epoch 12/Step 10, Loss Generator: 0.8293, Loss Discriminator: 0.0419, Accuracy Dis: 0.9979\n",
      "Epoch 12/Step 15, Loss Generator: 0.8491, Loss Discriminator: 0.0459, Accuracy Dis: 0.9956\n",
      "Epoch 12/Step 20, Loss Generator: 0.8746, Loss Discriminator: 0.0283, Accuracy Dis: 0.9967\n",
      "Epoch 12/Step 25, Loss Generator: 0.8497, Loss Discriminator: 0.0406, Accuracy Dis: 0.9964\n",
      "Decrease disc training frequency to every 10 steps\n",
      "Saving images\n",
      "\n",
      "Start of epoch 13\n",
      "Epoch 13/Step 0, Loss Generator: 0.8350, Loss Discriminator: 0.0364, Accuracy Dis: 1.0000\n",
      "Epoch 13/Step 5, Loss Generator: 0.8399, Loss Discriminator: 0.0346, Accuracy Dis: 0.9987\n",
      "Epoch 13/Step 10, Loss Generator: 0.7994, Loss Discriminator: 0.0546, Accuracy Dis: 0.9972\n",
      "Epoch 13/Step 15, Loss Generator: 0.7816, Loss Discriminator: 0.0324, Accuracy Dis: 0.9946\n",
      "Epoch 13/Step 20, Loss Generator: 0.7825, Loss Discriminator: 0.0414, Accuracy Dis: 0.9955\n",
      "Epoch 13/Step 25, Loss Generator: 0.8422, Loss Discriminator: 0.0299, Accuracy Dis: 0.9958\n",
      "Saving images\n",
      "\n",
      "Start of epoch 14\n",
      "Epoch 14/Step 0, Loss Generator: 0.8548, Loss Discriminator: 0.0435, Accuracy Dis: 0.9922\n",
      "Epoch 14/Step 5, Loss Generator: 0.7901, Loss Discriminator: 0.0421, Accuracy Dis: 0.9974\n",
      "Epoch 14/Step 10, Loss Generator: 0.8892, Loss Discriminator: 0.0366, Accuracy Dis: 0.9957\n",
      "Epoch 14/Step 15, Loss Generator: 0.8623, Loss Discriminator: 0.0458, Accuracy Dis: 0.9961\n",
      "Epoch 14/Step 20, Loss Generator: 0.9014, Loss Discriminator: 0.0280, Accuracy Dis: 0.9967\n",
      "Epoch 14/Step 25, Loss Generator: 0.8365, Loss Discriminator: 0.0465, Accuracy Dis: 0.9964\n",
      "Saving images\n",
      "\n",
      "Start of epoch 15\n",
      "Epoch 15/Step 0, Loss Generator: 0.8027, Loss Discriminator: 0.0367, Accuracy Dis: 1.0000\n",
      "Epoch 15/Step 5, Loss Generator: 0.7894, Loss Discriminator: 0.0696, Accuracy Dis: 0.9961\n",
      "Epoch 15/Step 10, Loss Generator: 0.8067, Loss Discriminator: 0.0582, Accuracy Dis: 0.9950\n",
      "Epoch 15/Step 15, Loss Generator: 0.8939, Loss Discriminator: 0.0314, Accuracy Dis: 0.9966\n",
      "Epoch 15/Step 20, Loss Generator: 0.8516, Loss Discriminator: 0.0349, Accuracy Dis: 0.9955\n",
      "Epoch 15/Step 25, Loss Generator: 0.8148, Loss Discriminator: 0.0429, Accuracy Dis: 0.9964\n",
      "Saving images\n",
      "\n",
      "Start of epoch 16\n",
      "Epoch 16/Step 0, Loss Generator: 0.7894, Loss Discriminator: 0.0629, Accuracy Dis: 0.9922\n",
      "Epoch 16/Step 5, Loss Generator: 0.8984, Loss Discriminator: 0.0361, Accuracy Dis: 0.9987\n",
      "Epoch 16/Step 10, Loss Generator: 0.8422, Loss Discriminator: 0.0415, Accuracy Dis: 0.9964\n",
      "Epoch 16/Step 15, Loss Generator: 0.8839, Loss Discriminator: 0.0462, Accuracy Dis: 0.9971\n",
      "Epoch 16/Step 20, Loss Generator: 0.9039, Loss Discriminator: 0.0557, Accuracy Dis: 0.9970\n",
      "Epoch 16/Step 25, Loss Generator: 0.7658, Loss Discriminator: 0.0624, Accuracy Dis: 0.9967\n",
      "Saving images\n",
      "\n",
      "Start of epoch 17\n",
      "Epoch 17/Step 0, Loss Generator: 0.9082, Loss Discriminator: 0.0550, Accuracy Dis: 1.0000\n",
      "Epoch 17/Step 5, Loss Generator: 0.8086, Loss Discriminator: 0.0435, Accuracy Dis: 0.9987\n",
      "Epoch 17/Step 10, Loss Generator: 0.8264, Loss Discriminator: 0.0830, Accuracy Dis: 0.9979\n",
      "Epoch 17/Step 15, Loss Generator: 0.8300, Loss Discriminator: 0.0307, Accuracy Dis: 0.9966\n",
      "Epoch 17/Step 20, Loss Generator: 0.7270, Loss Discriminator: 0.0579, Accuracy Dis: 0.9974\n",
      "Epoch 17/Step 25, Loss Generator: 0.8150, Loss Discriminator: 0.0403, Accuracy Dis: 0.9973\n",
      "Saving images\n",
      "\n",
      "Start of epoch 18\n",
      "Epoch 18/Step 0, Loss Generator: 0.8681, Loss Discriminator: 0.0791, Accuracy Dis: 0.9922\n",
      "Epoch 18/Step 5, Loss Generator: 0.8712, Loss Discriminator: 0.0804, Accuracy Dis: 0.9922\n",
      "Epoch 18/Step 10, Loss Generator: 0.7361, Loss Discriminator: 0.0643, Accuracy Dis: 0.9908\n",
      "Epoch 18/Step 15, Loss Generator: 0.8579, Loss Discriminator: 0.0348, Accuracy Dis: 0.9917\n",
      "Epoch 18/Step 20, Loss Generator: 0.6997, Loss Discriminator: 0.0781, Accuracy Dis: 0.9892\n",
      "Epoch 18/Step 25, Loss Generator: 0.6957, Loss Discriminator: 0.0662, Accuracy Dis: 0.9904\n",
      "Saving images\n",
      "\n",
      "Start of epoch 19\n",
      "Epoch 19/Step 0, Loss Generator: 0.8020, Loss Discriminator: 0.0543, Accuracy Dis: 0.9922\n",
      "Epoch 19/Step 5, Loss Generator: 0.8322, Loss Discriminator: 0.0446, Accuracy Dis: 0.9909\n",
      "Epoch 19/Step 10, Loss Generator: 0.7504, Loss Discriminator: 0.0715, Accuracy Dis: 0.9901\n",
      "Epoch 19/Step 15, Loss Generator: 0.8724, Loss Discriminator: 0.0982, Accuracy Dis: 0.9897\n",
      "Epoch 19/Step 20, Loss Generator: 0.7812, Loss Discriminator: 0.0450, Accuracy Dis: 0.9914\n",
      "Epoch 19/Step 25, Loss Generator: 0.8903, Loss Discriminator: 0.0356, Accuracy Dis: 0.9907\n",
      "Saving images\n",
      "\n",
      "Start of epoch 20\n",
      "Epoch 20/Step 0, Loss Generator: 0.9168, Loss Discriminator: 0.0460, Accuracy Dis: 0.9922\n",
      "Epoch 20/Step 5, Loss Generator: 0.8835, Loss Discriminator: 0.1144, Accuracy Dis: 0.9909\n",
      "Epoch 20/Step 10, Loss Generator: 0.8306, Loss Discriminator: 0.0803, Accuracy Dis: 0.9908\n",
      "Epoch 20/Step 15, Loss Generator: 0.7731, Loss Discriminator: 0.0769, Accuracy Dis: 0.9917\n",
      "Epoch 20/Step 20, Loss Generator: 0.8098, Loss Discriminator: 0.0891, Accuracy Dis: 0.9911\n",
      "Epoch 20/Step 25, Loss Generator: 0.7973, Loss Discriminator: 0.0631, Accuracy Dis: 0.9913\n",
      "Saving images\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_20/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_20/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_20/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_20/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 21\n",
      "Epoch 21/Step 0, Loss Generator: 0.7666, Loss Discriminator: 0.0819, Accuracy Dis: 0.9844\n",
      "Epoch 21/Step 5, Loss Generator: 0.9100, Loss Discriminator: 0.0603, Accuracy Dis: 0.9896\n",
      "Epoch 21/Step 10, Loss Generator: 0.9478, Loss Discriminator: 0.0923, Accuracy Dis: 0.9858\n",
      "Epoch 21/Step 15, Loss Generator: 0.9191, Loss Discriminator: 0.0684, Accuracy Dis: 0.9893\n",
      "Epoch 21/Step 20, Loss Generator: 0.9356, Loss Discriminator: 0.0672, Accuracy Dis: 0.9914\n",
      "Epoch 21/Step 25, Loss Generator: 0.9437, Loss Discriminator: 0.0621, Accuracy Dis: 0.9916\n",
      "Saving images\n",
      "\n",
      "Start of epoch 22\n",
      "Epoch 22/Step 0, Loss Generator: 1.0104, Loss Discriminator: 0.0444, Accuracy Dis: 1.0000\n",
      "Epoch 22/Step 5, Loss Generator: 0.8725, Loss Discriminator: 0.0677, Accuracy Dis: 0.9922\n",
      "Epoch 22/Step 10, Loss Generator: 0.9185, Loss Discriminator: 0.0637, Accuracy Dis: 0.9901\n",
      "Epoch 22/Step 15, Loss Generator: 0.9249, Loss Discriminator: 0.0512, Accuracy Dis: 0.9893\n",
      "Epoch 22/Step 20, Loss Generator: 0.8441, Loss Discriminator: 0.0505, Accuracy Dis: 0.9900\n",
      "Epoch 22/Step 25, Loss Generator: 0.8854, Loss Discriminator: 0.1086, Accuracy Dis: 0.9889\n",
      "Saving images\n",
      "\n",
      "Start of epoch 23\n",
      "Epoch 23/Step 0, Loss Generator: 0.8901, Loss Discriminator: 0.0676, Accuracy Dis: 0.9844\n",
      "Epoch 23/Step 5, Loss Generator: 0.8641, Loss Discriminator: 0.0656, Accuracy Dis: 0.9961\n",
      "Epoch 23/Step 10, Loss Generator: 0.8956, Loss Discriminator: 0.0780, Accuracy Dis: 0.9901\n",
      "Epoch 23/Step 15, Loss Generator: 0.9043, Loss Discriminator: 0.0445, Accuracy Dis: 0.9917\n",
      "Epoch 23/Step 20, Loss Generator: 0.9723, Loss Discriminator: 0.0593, Accuracy Dis: 0.9914\n",
      "Epoch 23/Step 25, Loss Generator: 0.8221, Loss Discriminator: 0.0582, Accuracy Dis: 0.9922\n",
      "Saving images\n",
      "\n",
      "Start of epoch 24\n",
      "Epoch 24/Step 0, Loss Generator: 0.8693, Loss Discriminator: 0.0511, Accuracy Dis: 0.9844\n",
      "Epoch 24/Step 5, Loss Generator: 0.8932, Loss Discriminator: 0.0632, Accuracy Dis: 0.9857\n",
      "Epoch 24/Step 10, Loss Generator: 0.8862, Loss Discriminator: 0.0421, Accuracy Dis: 0.9901\n",
      "Epoch 24/Step 15, Loss Generator: 0.8982, Loss Discriminator: 0.0560, Accuracy Dis: 0.9902\n",
      "Epoch 24/Step 20, Loss Generator: 0.9074, Loss Discriminator: 0.0580, Accuracy Dis: 0.9918\n",
      "Epoch 24/Step 25, Loss Generator: 0.8700, Loss Discriminator: 0.0877, Accuracy Dis: 0.9919\n",
      "Saving images\n",
      "\n",
      "Start of epoch 25\n",
      "Epoch 25/Step 0, Loss Generator: 0.9203, Loss Discriminator: 0.0483, Accuracy Dis: 1.0000\n",
      "Epoch 25/Step 5, Loss Generator: 0.8356, Loss Discriminator: 0.0467, Accuracy Dis: 0.9948\n",
      "Epoch 25/Step 10, Loss Generator: 0.9370, Loss Discriminator: 0.0451, Accuracy Dis: 0.9943\n",
      "Epoch 25/Step 15, Loss Generator: 0.8222, Loss Discriminator: 0.0722, Accuracy Dis: 0.9937\n",
      "Epoch 25/Step 20, Loss Generator: 0.8242, Loss Discriminator: 0.0605, Accuracy Dis: 0.9926\n",
      "Epoch 25/Step 25, Loss Generator: 0.7807, Loss Discriminator: 0.0680, Accuracy Dis: 0.9928\n",
      "Saving images\n",
      "\n",
      "Start of epoch 26\n",
      "Epoch 26/Step 0, Loss Generator: 0.8735, Loss Discriminator: 0.0549, Accuracy Dis: 0.9922\n",
      "Epoch 26/Step 5, Loss Generator: 0.9223, Loss Discriminator: 0.0608, Accuracy Dis: 0.9948\n",
      "Epoch 26/Step 10, Loss Generator: 0.8122, Loss Discriminator: 0.0549, Accuracy Dis: 0.9957\n",
      "Epoch 26/Step 15, Loss Generator: 0.8041, Loss Discriminator: 0.0553, Accuracy Dis: 0.9951\n",
      "Epoch 26/Step 20, Loss Generator: 0.9063, Loss Discriminator: 0.0640, Accuracy Dis: 0.9948\n",
      "Epoch 26/Step 25, Loss Generator: 0.8947, Loss Discriminator: 0.0463, Accuracy Dis: 0.9952\n",
      "Saving images\n",
      "\n",
      "Start of epoch 27\n",
      "Epoch 27/Step 0, Loss Generator: 0.8521, Loss Discriminator: 0.0605, Accuracy Dis: 0.9922\n",
      "Epoch 27/Step 5, Loss Generator: 0.8031, Loss Discriminator: 0.0642, Accuracy Dis: 0.9935\n",
      "Epoch 27/Step 10, Loss Generator: 0.8845, Loss Discriminator: 0.0466, Accuracy Dis: 0.9893\n",
      "Epoch 27/Step 15, Loss Generator: 0.8501, Loss Discriminator: 0.0558, Accuracy Dis: 0.9917\n",
      "Epoch 27/Step 20, Loss Generator: 0.8093, Loss Discriminator: 0.0798, Accuracy Dis: 0.9918\n",
      "Epoch 27/Step 25, Loss Generator: 0.8198, Loss Discriminator: 0.0575, Accuracy Dis: 0.9928\n",
      "Saving images\n",
      "\n",
      "Start of epoch 28\n",
      "Epoch 28/Step 0, Loss Generator: 0.7407, Loss Discriminator: 0.0791, Accuracy Dis: 1.0000\n",
      "Epoch 28/Step 5, Loss Generator: 0.8648, Loss Discriminator: 0.0603, Accuracy Dis: 0.9883\n",
      "Epoch 28/Step 10, Loss Generator: 0.7437, Loss Discriminator: 0.0670, Accuracy Dis: 0.9901\n",
      "Epoch 28/Step 15, Loss Generator: 0.9493, Loss Discriminator: 0.0409, Accuracy Dis: 0.9912\n",
      "Epoch 28/Step 20, Loss Generator: 0.9805, Loss Discriminator: 0.0539, Accuracy Dis: 0.9922\n",
      "Epoch 28/Step 25, Loss Generator: 0.9691, Loss Discriminator: 0.0724, Accuracy Dis: 0.9913\n",
      "Saving images\n",
      "\n",
      "Start of epoch 29\n",
      "Epoch 29/Step 0, Loss Generator: 0.9492, Loss Discriminator: 0.0373, Accuracy Dis: 0.9922\n",
      "Epoch 29/Step 5, Loss Generator: 1.0499, Loss Discriminator: 0.0708, Accuracy Dis: 0.9896\n",
      "Epoch 29/Step 10, Loss Generator: 1.0033, Loss Discriminator: 0.0871, Accuracy Dis: 0.9893\n",
      "Epoch 29/Step 15, Loss Generator: 0.9495, Loss Discriminator: 0.0552, Accuracy Dis: 0.9868\n",
      "Epoch 29/Step 20, Loss Generator: 1.0104, Loss Discriminator: 0.0457, Accuracy Dis: 0.9888\n",
      "Epoch 29/Step 25, Loss Generator: 0.9503, Loss Discriminator: 0.0802, Accuracy Dis: 0.9886\n",
      "Saving images\n",
      "\n",
      "Start of epoch 30\n",
      "Epoch 30/Step 0, Loss Generator: 0.9015, Loss Discriminator: 0.0530, Accuracy Dis: 0.9922\n",
      "Epoch 30/Step 5, Loss Generator: 0.9884, Loss Discriminator: 0.0778, Accuracy Dis: 0.9896\n",
      "Epoch 30/Step 10, Loss Generator: 0.9135, Loss Discriminator: 0.0460, Accuracy Dis: 0.9879\n",
      "Epoch 30/Step 15, Loss Generator: 1.0029, Loss Discriminator: 0.0668, Accuracy Dis: 0.9858\n",
      "Epoch 30/Step 20, Loss Generator: 0.9541, Loss Discriminator: 0.0545, Accuracy Dis: 0.9851\n",
      "Epoch 30/Step 25, Loss Generator: 0.9215, Loss Discriminator: 0.0618, Accuracy Dis: 0.9850\n",
      "Saving images\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_30/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_30/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_30/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_30/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 31\n",
      "Epoch 31/Step 0, Loss Generator: 0.8999, Loss Discriminator: 0.0813, Accuracy Dis: 0.9766\n",
      "Epoch 31/Step 5, Loss Generator: 0.9156, Loss Discriminator: 0.0582, Accuracy Dis: 0.9896\n",
      "Epoch 31/Step 10, Loss Generator: 0.8775, Loss Discriminator: 0.0436, Accuracy Dis: 0.9901\n",
      "Epoch 31/Step 15, Loss Generator: 0.8224, Loss Discriminator: 0.0558, Accuracy Dis: 0.9897\n",
      "Epoch 31/Step 20, Loss Generator: 0.9449, Loss Discriminator: 0.0496, Accuracy Dis: 0.9896\n",
      "Epoch 31/Step 25, Loss Generator: 0.7831, Loss Discriminator: 0.0626, Accuracy Dis: 0.9892\n",
      "Saving images\n",
      "\n",
      "Start of epoch 32\n",
      "Epoch 32/Step 0, Loss Generator: 0.8097, Loss Discriminator: 0.0378, Accuracy Dis: 1.0000\n",
      "Epoch 32/Step 5, Loss Generator: 0.9541, Loss Discriminator: 0.0979, Accuracy Dis: 0.9883\n",
      "Epoch 32/Step 10, Loss Generator: 0.7905, Loss Discriminator: 0.0560, Accuracy Dis: 0.9879\n",
      "Epoch 32/Step 15, Loss Generator: 0.8922, Loss Discriminator: 0.0519, Accuracy Dis: 0.9858\n",
      "Epoch 32/Step 20, Loss Generator: 0.8370, Loss Discriminator: 0.0484, Accuracy Dis: 0.9855\n",
      "Epoch 32/Step 25, Loss Generator: 0.8399, Loss Discriminator: 0.0521, Accuracy Dis: 0.9868\n",
      "Saving images\n",
      "\n",
      "Start of epoch 33\n",
      "Epoch 33/Step 0, Loss Generator: 0.7805, Loss Discriminator: 0.0432, Accuracy Dis: 1.0000\n",
      "Epoch 33/Step 5, Loss Generator: 0.8051, Loss Discriminator: 0.0534, Accuracy Dis: 0.9948\n",
      "Epoch 33/Step 10, Loss Generator: 0.7814, Loss Discriminator: 0.0790, Accuracy Dis: 0.9929\n",
      "Epoch 33/Step 15, Loss Generator: 0.8655, Loss Discriminator: 0.0411, Accuracy Dis: 0.9922\n",
      "Epoch 33/Step 20, Loss Generator: 0.8605, Loss Discriminator: 0.0541, Accuracy Dis: 0.9929\n",
      "Epoch 33/Step 25, Loss Generator: 1.1580, Loss Discriminator: 0.0948, Accuracy Dis: 0.9934\n",
      "Saving images\n",
      "\n",
      "Start of epoch 34\n",
      "Epoch 34/Step 0, Loss Generator: 0.9702, Loss Discriminator: 0.0368, Accuracy Dis: 0.9922\n",
      "Epoch 34/Step 5, Loss Generator: 1.0208, Loss Discriminator: 0.0586, Accuracy Dis: 0.9896\n",
      "Epoch 34/Step 10, Loss Generator: 0.9650, Loss Discriminator: 0.0430, Accuracy Dis: 0.9922\n",
      "Epoch 34/Step 15, Loss Generator: 1.0045, Loss Discriminator: 0.0374, Accuracy Dis: 0.9912\n",
      "Epoch 34/Step 20, Loss Generator: 1.0629, Loss Discriminator: 0.0771, Accuracy Dis: 0.9918\n",
      "Epoch 34/Step 25, Loss Generator: 0.9551, Loss Discriminator: 0.0281, Accuracy Dis: 0.9934\n",
      "Saving images\n",
      "\n",
      "Start of epoch 35\n",
      "Epoch 35/Step 0, Loss Generator: 1.0184, Loss Discriminator: 0.0555, Accuracy Dis: 0.9922\n",
      "Epoch 35/Step 5, Loss Generator: 0.9632, Loss Discriminator: 0.0429, Accuracy Dis: 0.9974\n",
      "Epoch 35/Step 10, Loss Generator: 0.9475, Loss Discriminator: 0.0421, Accuracy Dis: 0.9964\n",
      "Epoch 35/Step 15, Loss Generator: 0.9797, Loss Discriminator: 0.0446, Accuracy Dis: 0.9956\n",
      "Epoch 35/Step 20, Loss Generator: 0.9396, Loss Discriminator: 0.0280, Accuracy Dis: 0.9955\n",
      "Epoch 35/Step 25, Loss Generator: 1.0212, Loss Discriminator: 0.0376, Accuracy Dis: 0.9952\n",
      "Saving images\n",
      "\n",
      "Start of epoch 36\n",
      "Epoch 36/Step 0, Loss Generator: 0.9575, Loss Discriminator: 0.0346, Accuracy Dis: 1.0000\n",
      "Epoch 36/Step 5, Loss Generator: 0.9239, Loss Discriminator: 0.0499, Accuracy Dis: 0.9948\n",
      "Epoch 36/Step 10, Loss Generator: 0.8583, Loss Discriminator: 0.0415, Accuracy Dis: 0.9964\n",
      "Epoch 36/Step 15, Loss Generator: 0.9019, Loss Discriminator: 0.0288, Accuracy Dis: 0.9961\n",
      "Epoch 36/Step 20, Loss Generator: 0.8994, Loss Discriminator: 0.0540, Accuracy Dis: 0.9948\n",
      "Epoch 36/Step 25, Loss Generator: 0.9743, Loss Discriminator: 0.0672, Accuracy Dis: 0.9943\n",
      "Saving images\n",
      "\n",
      "Start of epoch 37\n",
      "Epoch 37/Step 0, Loss Generator: 0.8539, Loss Discriminator: 0.0730, Accuracy Dis: 0.9922\n",
      "Epoch 37/Step 5, Loss Generator: 0.9612, Loss Discriminator: 0.0479, Accuracy Dis: 0.9896\n",
      "Epoch 37/Step 10, Loss Generator: 0.9566, Loss Discriminator: 0.0363, Accuracy Dis: 0.9929\n",
      "Epoch 37/Step 15, Loss Generator: 0.9737, Loss Discriminator: 0.0537, Accuracy Dis: 0.9917\n",
      "Epoch 37/Step 20, Loss Generator: 1.0073, Loss Discriminator: 0.0395, Accuracy Dis: 0.9926\n",
      "Epoch 37/Step 25, Loss Generator: 0.8252, Loss Discriminator: 0.0529, Accuracy Dis: 0.9937\n",
      "Saving images\n",
      "\n",
      "Start of epoch 38\n",
      "Epoch 38/Step 0, Loss Generator: 0.8587, Loss Discriminator: 0.0563, Accuracy Dis: 0.9844\n",
      "Epoch 38/Step 5, Loss Generator: 0.8997, Loss Discriminator: 0.0458, Accuracy Dis: 0.9961\n",
      "Epoch 38/Step 10, Loss Generator: 0.8523, Loss Discriminator: 0.0759, Accuracy Dis: 0.9943\n",
      "Epoch 38/Step 15, Loss Generator: 0.9157, Loss Discriminator: 0.0570, Accuracy Dis: 0.9946\n",
      "Epoch 38/Step 20, Loss Generator: 0.9284, Loss Discriminator: 0.0429, Accuracy Dis: 0.9944\n",
      "Epoch 38/Step 25, Loss Generator: 0.8987, Loss Discriminator: 0.0779, Accuracy Dis: 0.9943\n",
      "Saving images\n",
      "\n",
      "Start of epoch 39\n",
      "Epoch 39/Step 0, Loss Generator: 0.8480, Loss Discriminator: 0.0366, Accuracy Dis: 1.0000\n",
      "Epoch 39/Step 5, Loss Generator: 0.8321, Loss Discriminator: 0.0474, Accuracy Dis: 0.9935\n",
      "Epoch 39/Step 10, Loss Generator: 0.9310, Loss Discriminator: 0.0373, Accuracy Dis: 0.9957\n",
      "Epoch 39/Step 15, Loss Generator: 0.8164, Loss Discriminator: 0.0466, Accuracy Dis: 0.9951\n",
      "Epoch 39/Step 20, Loss Generator: 0.8616, Loss Discriminator: 0.0266, Accuracy Dis: 0.9955\n",
      "Epoch 39/Step 25, Loss Generator: 0.8618, Loss Discriminator: 0.0480, Accuracy Dis: 0.9958\n",
      "Saving images\n",
      "\n",
      "Start of epoch 40\n",
      "Epoch 40/Step 0, Loss Generator: 1.1019, Loss Discriminator: 0.0811, Accuracy Dis: 1.0000\n",
      "Epoch 40/Step 5, Loss Generator: 0.8633, Loss Discriminator: 0.0508, Accuracy Dis: 0.9961\n",
      "Epoch 40/Step 10, Loss Generator: 0.9159, Loss Discriminator: 0.0308, Accuracy Dis: 0.9943\n",
      "Epoch 40/Step 15, Loss Generator: 0.8886, Loss Discriminator: 0.0352, Accuracy Dis: 0.9946\n",
      "Epoch 40/Step 20, Loss Generator: 0.8705, Loss Discriminator: 0.0373, Accuracy Dis: 0.9952\n",
      "Epoch 40/Step 25, Loss Generator: 0.8689, Loss Discriminator: 0.0630, Accuracy Dis: 0.9958\n",
      "Saving images\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_40/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_40/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_40/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_40/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 41\n",
      "Epoch 41/Step 0, Loss Generator: 0.9512, Loss Discriminator: 0.0445, Accuracy Dis: 0.9922\n",
      "Epoch 41/Step 5, Loss Generator: 0.8273, Loss Discriminator: 0.0346, Accuracy Dis: 0.9974\n",
      "Epoch 41/Step 10, Loss Generator: 0.8683, Loss Discriminator: 0.0482, Accuracy Dis: 0.9964\n",
      "Epoch 41/Step 15, Loss Generator: 0.9336, Loss Discriminator: 0.0374, Accuracy Dis: 0.9956\n",
      "Epoch 41/Step 20, Loss Generator: 0.8883, Loss Discriminator: 0.0380, Accuracy Dis: 0.9955\n",
      "Epoch 41/Step 25, Loss Generator: 0.8142, Loss Discriminator: 0.0612, Accuracy Dis: 0.9955\n",
      "Saving images\n",
      "\n",
      "Start of epoch 42\n",
      "Epoch 42/Step 0, Loss Generator: 0.8473, Loss Discriminator: 0.0391, Accuracy Dis: 1.0000\n",
      "Epoch 42/Step 5, Loss Generator: 0.8299, Loss Discriminator: 0.0395, Accuracy Dis: 1.0000\n",
      "Epoch 42/Step 10, Loss Generator: 0.9444, Loss Discriminator: 0.0691, Accuracy Dis: 0.9979\n",
      "Epoch 42/Step 15, Loss Generator: 0.8849, Loss Discriminator: 0.0235, Accuracy Dis: 0.9966\n",
      "Epoch 42/Step 20, Loss Generator: 0.8903, Loss Discriminator: 0.0387, Accuracy Dis: 0.9963\n",
      "Epoch 42/Step 25, Loss Generator: 0.8592, Loss Discriminator: 0.0454, Accuracy Dis: 0.9961\n",
      "Saving images\n",
      "\n",
      "Start of epoch 43\n",
      "Epoch 43/Step 0, Loss Generator: 0.8779, Loss Discriminator: 0.0455, Accuracy Dis: 0.9844\n",
      "Epoch 43/Step 5, Loss Generator: 0.8496, Loss Discriminator: 0.0353, Accuracy Dis: 0.9935\n",
      "Epoch 43/Step 10, Loss Generator: 0.8731, Loss Discriminator: 0.0586, Accuracy Dis: 0.9915\n",
      "Epoch 43/Step 15, Loss Generator: 0.8931, Loss Discriminator: 0.0237, Accuracy Dis: 0.9922\n",
      "Epoch 43/Step 20, Loss Generator: 0.9276, Loss Discriminator: 0.0482, Accuracy Dis: 0.9929\n",
      "Epoch 43/Step 25, Loss Generator: 0.9215, Loss Discriminator: 0.0361, Accuracy Dis: 0.9937\n",
      "Saving images\n",
      "\n",
      "Start of epoch 44\n",
      "Epoch 44/Step 0, Loss Generator: 0.8891, Loss Discriminator: 0.0299, Accuracy Dis: 1.0000\n",
      "Epoch 44/Step 5, Loss Generator: 0.8395, Loss Discriminator: 0.0290, Accuracy Dis: 1.0000\n",
      "Epoch 44/Step 10, Loss Generator: 0.8988, Loss Discriminator: 0.0303, Accuracy Dis: 0.9979\n",
      "Epoch 44/Step 15, Loss Generator: 0.9289, Loss Discriminator: 0.0340, Accuracy Dis: 0.9980\n",
      "Epoch 44/Step 20, Loss Generator: 0.8383, Loss Discriminator: 0.0254, Accuracy Dis: 0.9978\n",
      "Epoch 44/Step 25, Loss Generator: 0.8983, Loss Discriminator: 0.0359, Accuracy Dis: 0.9970\n",
      "Saving images\n",
      "\n",
      "Start of epoch 45\n",
      "Epoch 45/Step 0, Loss Generator: 0.9291, Loss Discriminator: 0.0320, Accuracy Dis: 0.9922\n",
      "Epoch 45/Step 5, Loss Generator: 0.8753, Loss Discriminator: 0.0343, Accuracy Dis: 0.9948\n",
      "Epoch 45/Step 10, Loss Generator: 0.9272, Loss Discriminator: 0.0268, Accuracy Dis: 0.9943\n",
      "Epoch 45/Step 15, Loss Generator: 0.9107, Loss Discriminator: 0.0228, Accuracy Dis: 0.9951\n",
      "Epoch 45/Step 20, Loss Generator: 0.9312, Loss Discriminator: 0.0419, Accuracy Dis: 0.9952\n",
      "Epoch 45/Step 25, Loss Generator: 0.8990, Loss Discriminator: 0.0363, Accuracy Dis: 0.9955\n",
      "Saving images\n",
      "\n",
      "Start of epoch 46\n",
      "Epoch 46/Step 0, Loss Generator: 0.9077, Loss Discriminator: 0.0476, Accuracy Dis: 0.9922\n",
      "Epoch 46/Step 5, Loss Generator: 0.8850, Loss Discriminator: 0.0332, Accuracy Dis: 0.9974\n",
      "Epoch 46/Step 10, Loss Generator: 0.9665, Loss Discriminator: 0.0284, Accuracy Dis: 0.9950\n",
      "Epoch 46/Step 15, Loss Generator: 0.9022, Loss Discriminator: 0.0482, Accuracy Dis: 0.9946\n",
      "Epoch 46/Step 20, Loss Generator: 0.9204, Loss Discriminator: 0.0342, Accuracy Dis: 0.9948\n",
      "Epoch 46/Step 25, Loss Generator: 0.9573, Loss Discriminator: 0.0617, Accuracy Dis: 0.9949\n",
      "Saving images\n",
      "\n",
      "Start of epoch 47\n",
      "Epoch 47/Step 0, Loss Generator: 0.8937, Loss Discriminator: 0.0327, Accuracy Dis: 0.9844\n",
      "Epoch 47/Step 5, Loss Generator: 0.9595, Loss Discriminator: 0.0213, Accuracy Dis: 0.9948\n",
      "Epoch 47/Step 10, Loss Generator: 0.8762, Loss Discriminator: 0.0455, Accuracy Dis: 0.9901\n",
      "Epoch 47/Step 15, Loss Generator: 0.9091, Loss Discriminator: 0.0505, Accuracy Dis: 0.9897\n",
      "Epoch 47/Step 20, Loss Generator: 0.9107, Loss Discriminator: 0.0530, Accuracy Dis: 0.9914\n",
      "Epoch 47/Step 25, Loss Generator: 0.9166, Loss Discriminator: 0.0318, Accuracy Dis: 0.9922\n",
      "Saving images\n",
      "\n",
      "Start of epoch 48\n",
      "Epoch 48/Step 0, Loss Generator: 0.8624, Loss Discriminator: 0.0366, Accuracy Dis: 0.9922\n",
      "Epoch 48/Step 5, Loss Generator: 0.8757, Loss Discriminator: 0.0322, Accuracy Dis: 0.9974\n",
      "Epoch 48/Step 10, Loss Generator: 0.9744, Loss Discriminator: 0.0281, Accuracy Dis: 0.9972\n",
      "Epoch 48/Step 15, Loss Generator: 0.9301, Loss Discriminator: 0.0275, Accuracy Dis: 0.9966\n",
      "Epoch 48/Step 20, Loss Generator: 0.9761, Loss Discriminator: 0.0400, Accuracy Dis: 0.9967\n",
      "Epoch 48/Step 25, Loss Generator: 1.0293, Loss Discriminator: 0.0367, Accuracy Dis: 0.9970\n",
      "Saving images\n",
      "\n",
      "Start of epoch 49\n",
      "Epoch 49/Step 0, Loss Generator: 0.9205, Loss Discriminator: 0.0242, Accuracy Dis: 1.0000\n",
      "Epoch 49/Step 5, Loss Generator: 0.9820, Loss Discriminator: 0.0274, Accuracy Dis: 0.9974\n",
      "Epoch 49/Step 10, Loss Generator: 0.8778, Loss Discriminator: 0.0292, Accuracy Dis: 0.9972\n",
      "Epoch 49/Step 15, Loss Generator: 0.9621, Loss Discriminator: 0.0284, Accuracy Dis: 0.9976\n",
      "Epoch 49/Step 20, Loss Generator: 0.9426, Loss Discriminator: 0.0242, Accuracy Dis: 0.9978\n",
      "Epoch 49/Step 25, Loss Generator: 0.9581, Loss Discriminator: 0.0465, Accuracy Dis: 0.9973\n",
      "Saving images\n",
      "\n",
      "Start of epoch 50\n",
      "Epoch 50/Step 0, Loss Generator: 0.9463, Loss Discriminator: 0.0282, Accuracy Dis: 1.0000\n",
      "Epoch 50/Step 5, Loss Generator: 0.9439, Loss Discriminator: 0.0256, Accuracy Dis: 0.9987\n",
      "Epoch 50/Step 10, Loss Generator: 0.8838, Loss Discriminator: 0.0253, Accuracy Dis: 0.9972\n",
      "Epoch 50/Step 15, Loss Generator: 1.0847, Loss Discriminator: 0.0442, Accuracy Dis: 0.9971\n",
      "Epoch 50/Step 20, Loss Generator: 0.9322, Loss Discriminator: 0.0299, Accuracy Dis: 0.9974\n",
      "Epoch 50/Step 25, Loss Generator: 0.9577, Loss Discriminator: 0.0467, Accuracy Dis: 0.9976\n",
      "Saving images\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_50/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_50/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_50/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_50/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 51\n",
      "Epoch 51/Step 0, Loss Generator: 0.9633, Loss Discriminator: 0.0282, Accuracy Dis: 1.0000\n",
      "Epoch 51/Step 5, Loss Generator: 0.9385, Loss Discriminator: 0.0306, Accuracy Dis: 0.9948\n",
      "Epoch 51/Step 10, Loss Generator: 1.0055, Loss Discriminator: 0.0615, Accuracy Dis: 0.9957\n",
      "Epoch 51/Step 15, Loss Generator: 1.0115, Loss Discriminator: 0.0400, Accuracy Dis: 0.9961\n",
      "Epoch 51/Step 20, Loss Generator: 0.9791, Loss Discriminator: 0.0310, Accuracy Dis: 0.9967\n",
      "Epoch 51/Step 25, Loss Generator: 0.9416, Loss Discriminator: 0.0404, Accuracy Dis: 0.9970\n",
      "Saving images\n",
      "\n",
      "Start of epoch 52\n",
      "Epoch 52/Step 0, Loss Generator: 0.9691, Loss Discriminator: 0.0292, Accuracy Dis: 1.0000\n",
      "Epoch 52/Step 5, Loss Generator: 0.8309, Loss Discriminator: 0.0380, Accuracy Dis: 0.9974\n",
      "Epoch 52/Step 10, Loss Generator: 0.9047, Loss Discriminator: 0.0331, Accuracy Dis: 0.9979\n",
      "Epoch 52/Step 15, Loss Generator: 1.0116, Loss Discriminator: 0.0402, Accuracy Dis: 0.9976\n",
      "Epoch 52/Step 20, Loss Generator: 0.8794, Loss Discriminator: 0.0402, Accuracy Dis: 0.9981\n",
      "Epoch 52/Step 25, Loss Generator: 0.9488, Loss Discriminator: 0.0349, Accuracy Dis: 0.9979\n",
      "Saving images\n",
      "\n",
      "Start of epoch 53\n",
      "Epoch 53/Step 0, Loss Generator: 1.0272, Loss Discriminator: 0.0290, Accuracy Dis: 1.0000\n",
      "Epoch 53/Step 5, Loss Generator: 0.9782, Loss Discriminator: 0.0296, Accuracy Dis: 1.0000\n",
      "Epoch 53/Step 10, Loss Generator: 0.9024, Loss Discriminator: 0.0289, Accuracy Dis: 0.9979\n",
      "Epoch 53/Step 15, Loss Generator: 0.9508, Loss Discriminator: 0.0392, Accuracy Dis: 0.9980\n",
      "Epoch 53/Step 20, Loss Generator: 0.8938, Loss Discriminator: 0.0245, Accuracy Dis: 0.9974\n",
      "Epoch 53/Step 25, Loss Generator: 0.9022, Loss Discriminator: 0.0309, Accuracy Dis: 0.9976\n",
      "Saving images\n",
      "\n",
      "Start of epoch 54\n",
      "Epoch 54/Step 0, Loss Generator: 0.9386, Loss Discriminator: 0.0299, Accuracy Dis: 1.0000\n",
      "Epoch 54/Step 5, Loss Generator: 0.9963, Loss Discriminator: 0.0312, Accuracy Dis: 0.9961\n",
      "Epoch 54/Step 10, Loss Generator: 0.8647, Loss Discriminator: 0.0406, Accuracy Dis: 0.9950\n",
      "Epoch 54/Step 15, Loss Generator: 0.9523, Loss Discriminator: 0.0300, Accuracy Dis: 0.9961\n",
      "Epoch 54/Step 20, Loss Generator: 1.0532, Loss Discriminator: 0.0306, Accuracy Dis: 0.9963\n",
      "Epoch 54/Step 25, Loss Generator: 0.9408, Loss Discriminator: 0.0306, Accuracy Dis: 0.9964\n",
      "Saving images\n",
      "\n",
      "Start of epoch 55\n",
      "Epoch 55/Step 0, Loss Generator: 1.0349, Loss Discriminator: 0.0542, Accuracy Dis: 1.0000\n",
      "Epoch 55/Step 5, Loss Generator: 1.0251, Loss Discriminator: 0.0306, Accuracy Dis: 0.9974\n",
      "Epoch 55/Step 10, Loss Generator: 1.0157, Loss Discriminator: 0.0320, Accuracy Dis: 0.9972\n",
      "Epoch 55/Step 15, Loss Generator: 0.9687, Loss Discriminator: 0.0360, Accuracy Dis: 0.9971\n",
      "Epoch 55/Step 20, Loss Generator: 0.9076, Loss Discriminator: 0.0361, Accuracy Dis: 0.9970\n",
      "Epoch 55/Step 25, Loss Generator: 0.8835, Loss Discriminator: 0.0272, Accuracy Dis: 0.9964\n",
      "Saving images\n",
      "\n",
      "Start of epoch 56\n",
      "Epoch 56/Step 0, Loss Generator: 0.9775, Loss Discriminator: 0.0330, Accuracy Dis: 1.0000\n",
      "Epoch 56/Step 5, Loss Generator: 0.9002, Loss Discriminator: 0.0312, Accuracy Dis: 1.0000\n",
      "Epoch 56/Step 10, Loss Generator: 0.8771, Loss Discriminator: 0.0293, Accuracy Dis: 0.9979\n",
      "Epoch 56/Step 15, Loss Generator: 1.0106, Loss Discriminator: 0.0435, Accuracy Dis: 0.9971\n",
      "Epoch 56/Step 20, Loss Generator: 0.9836, Loss Discriminator: 0.0402, Accuracy Dis: 0.9974\n",
      "Epoch 56/Step 25, Loss Generator: 0.9328, Loss Discriminator: 0.0409, Accuracy Dis: 0.9970\n",
      "Saving images\n",
      "\n",
      "Start of epoch 57\n",
      "Epoch 57/Step 0, Loss Generator: 1.0664, Loss Discriminator: 0.0453, Accuracy Dis: 1.0000\n",
      "Epoch 57/Step 5, Loss Generator: 0.8858, Loss Discriminator: 0.0292, Accuracy Dis: 1.0000\n",
      "Epoch 57/Step 10, Loss Generator: 0.9104, Loss Discriminator: 0.0214, Accuracy Dis: 0.9993\n",
      "Epoch 57/Step 15, Loss Generator: 0.9388, Loss Discriminator: 0.0310, Accuracy Dis: 0.9980\n",
      "Epoch 57/Step 20, Loss Generator: 0.9359, Loss Discriminator: 0.0316, Accuracy Dis: 0.9981\n",
      "Epoch 57/Step 25, Loss Generator: 0.8885, Loss Discriminator: 0.0401, Accuracy Dis: 0.9979\n",
      "Saving images\n",
      "\n",
      "Start of epoch 58\n",
      "Epoch 58/Step 0, Loss Generator: 0.9216, Loss Discriminator: 0.0165, Accuracy Dis: 1.0000\n",
      "Epoch 58/Step 5, Loss Generator: 0.9215, Loss Discriminator: 0.0236, Accuracy Dis: 0.9974\n",
      "Epoch 58/Step 10, Loss Generator: 0.9052, Loss Discriminator: 0.0420, Accuracy Dis: 0.9964\n",
      "Epoch 58/Step 15, Loss Generator: 0.9201, Loss Discriminator: 0.0332, Accuracy Dis: 0.9966\n",
      "Epoch 58/Step 20, Loss Generator: 0.9181, Loss Discriminator: 0.0309, Accuracy Dis: 0.9970\n",
      "Epoch 58/Step 25, Loss Generator: 0.9302, Loss Discriminator: 0.0351, Accuracy Dis: 0.9973\n",
      "Saving images\n",
      "\n",
      "Start of epoch 59\n",
      "Epoch 59/Step 0, Loss Generator: 0.9575, Loss Discriminator: 0.0262, Accuracy Dis: 1.0000\n",
      "Epoch 59/Step 5, Loss Generator: 0.9025, Loss Discriminator: 0.0282, Accuracy Dis: 0.9896\n",
      "Epoch 59/Step 10, Loss Generator: 0.9318, Loss Discriminator: 0.0207, Accuracy Dis: 0.9936\n",
      "Epoch 59/Step 15, Loss Generator: 0.9305, Loss Discriminator: 0.0300, Accuracy Dis: 0.9932\n",
      "Epoch 59/Step 20, Loss Generator: 0.9429, Loss Discriminator: 0.0352, Accuracy Dis: 0.9937\n",
      "Epoch 59/Step 25, Loss Generator: 0.9032, Loss Discriminator: 0.0612, Accuracy Dis: 0.9931\n",
      "Saving images\n",
      "\n",
      "Start of epoch 60\n",
      "Epoch 60/Step 0, Loss Generator: 0.9090, Loss Discriminator: 0.0665, Accuracy Dis: 0.9844\n",
      "Epoch 60/Step 5, Loss Generator: 0.8780, Loss Discriminator: 0.0595, Accuracy Dis: 0.9922\n",
      "Epoch 60/Step 10, Loss Generator: 0.9262, Loss Discriminator: 0.0292, Accuracy Dis: 0.9936\n",
      "Epoch 60/Step 15, Loss Generator: 0.8850, Loss Discriminator: 0.0341, Accuracy Dis: 0.9946\n",
      "Epoch 60/Step 20, Loss Generator: 0.9169, Loss Discriminator: 0.0308, Accuracy Dis: 0.9944\n",
      "Epoch 60/Step 25, Loss Generator: 0.9158, Loss Discriminator: 0.0293, Accuracy Dis: 0.9952\n",
      "Saving images\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_60/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/generator_epoch_60/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_60/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /mnt/e/ML/MonetGAN/discriminator_epoch_60/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 61\n",
      "Epoch 61/Step 0, Loss Generator: 0.9288, Loss Discriminator: 0.0422, Accuracy Dis: 0.9766\n",
      "Epoch 61/Step 5, Loss Generator: 0.9519, Loss Discriminator: 0.0229, Accuracy Dis: 0.9935\n",
      "Epoch 61/Step 10, Loss Generator: 0.9279, Loss Discriminator: 0.0428, Accuracy Dis: 0.9936\n",
      "Epoch 61/Step 15, Loss Generator: 0.9615, Loss Discriminator: 0.0231, Accuracy Dis: 0.9941\n",
      "Epoch 61/Step 20, Loss Generator: 0.9021, Loss Discriminator: 0.0534, Accuracy Dis: 0.9940\n",
      "Epoch 61/Step 25, Loss Generator: 0.9243, Loss Discriminator: 0.0257, Accuracy Dis: 0.9946\n",
      "Saving images\n",
      "\n",
      "Start of epoch 62\n",
      "Epoch 62/Step 0, Loss Generator: 0.8913, Loss Discriminator: 0.0301, Accuracy Dis: 1.0000\n",
      "Epoch 62/Step 5, Loss Generator: 0.8982, Loss Discriminator: 0.0357, Accuracy Dis: 1.0000\n",
      "Epoch 62/Step 10, Loss Generator: 0.9323, Loss Discriminator: 0.0456, Accuracy Dis: 0.9964\n",
      "Epoch 62/Step 15, Loss Generator: 0.9809, Loss Discriminator: 0.0348, Accuracy Dis: 0.9971\n",
      "Epoch 62/Step 20, Loss Generator: 0.9415, Loss Discriminator: 0.0205, Accuracy Dis: 0.9974\n",
      "Epoch 62/Step 25, Loss Generator: 1.0632, Loss Discriminator: 0.0454, Accuracy Dis: 0.9970\n",
      "Saving images\n",
      "\n",
      "Start of epoch 63\n",
      "Epoch 63/Step 0, Loss Generator: 0.9419, Loss Discriminator: 0.0210, Accuracy Dis: 1.0000\n",
      "Epoch 63/Step 5, Loss Generator: 1.0085, Loss Discriminator: 0.0503, Accuracy Dis: 0.9948\n",
      "Epoch 63/Step 10, Loss Generator: 1.0049, Loss Discriminator: 0.0352, Accuracy Dis: 0.9950\n",
      "Epoch 63/Step 15, Loss Generator: 0.9643, Loss Discriminator: 0.0447, Accuracy Dis: 0.9961\n",
      "Epoch 63/Step 20, Loss Generator: 0.9377, Loss Discriminator: 0.0429, Accuracy Dis: 0.9963\n",
      "Epoch 63/Step 25, Loss Generator: 0.9247, Loss Discriminator: 0.0380, Accuracy Dis: 0.9964\n",
      "Saving images\n",
      "\n",
      "Start of epoch 64\n",
      "Epoch 64/Step 0, Loss Generator: 0.9297, Loss Discriminator: 0.0185, Accuracy Dis: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mStart of epoch \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (epoch,))\n\u001b[1;32m    121\u001b[0m \u001b[39m# Iterate over the batches of the dataset.\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mfor\u001b[39;00m step, x_batch_train \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batchedDataset):\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m epoch\u001b[39m<\u001b[39mTd:\n\u001b[1;32m    124\u001b[0m         lossGen, lossDis \u001b[39m=\u001b[39m trainStepDis(x_batch_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:814\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    813\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    815\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    816\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:777\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 777\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    778\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    779\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    780\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    782\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3023\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3022\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3023\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3024\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[1;32m   3025\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[1;32m   3026\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3027\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE=64\n",
    "LOG_INTERVAL=5\n",
    "epochs = 200\n",
    "saveModel=True\n",
    "\n",
    "startEpoch=0\n",
    "\n",
    "Td=2\n",
    "Tg=2\n",
    "\n",
    "log_dir = \"./logs/\"+generator.name+\"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,\n",
    "                                                      write_graph=True, update_freq=5)\n",
    "\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "# Instantiate an optimizer .\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "optimizerGen = tf.keras.optimizers.Adam(learning_rate=2e-4)\n",
    "optimizerDis = tf.keras.optimizers.Adam(learning_rate=2e-4)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "lossFnGen = tf.keras.losses.MeanSquaredError()\n",
    "# lossFnGen = tf.keras.losses.BinaryCrossentropy()\n",
    "lossFnDis = tf.keras.losses.MeanSquaredError()\n",
    "# lossFnDis = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "accuracyDis = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "# batchedDataset = datasetMonet.batch(BATCH_SIZE, drop_remainder=False)\n",
    "datasetShuffled = dataset.shuffle(200)\n",
    "batchedDataset = datasetShuffled.batch(BATCH_SIZE, drop_remainder=False).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def trainStepGen(trueImages):\n",
    "    input = tf.random.uniform((BATCH_SIZE, 1024))\n",
    "    with tf.GradientTape() as tapeGen, tf.GradientTape() as tapeDis:\n",
    "        fakeImages = generator(input, training=True) \n",
    "\n",
    "        discOutputFake = discriminator(fakeImages, training=True)\n",
    "        discOutputTrue = discriminator(trueImages, training=True)\n",
    "\n",
    "        lossGen = lossFnGen(tf.ones_like(discOutputFake), discOutputFake)\n",
    "\n",
    "        lossDisTrue = lossFnDis(tf.ones_like(discOutputTrue), discOutputTrue)\n",
    "        lossDisFake = lossFnDis(tf.zeros_like(discOutputFake), discOutputFake)\n",
    "        totalLossDis = lossDisTrue + lossDisFake\n",
    "\n",
    "    gradsGen = tapeGen.gradient(lossGen, generator.trainable_weights)\n",
    "\n",
    "    accuracyDis.update_state(tf.zeros_like(discOutputFake), discOutputFake)\n",
    "    accuracyDis.update_state(tf.ones_like(discOutputTrue), discOutputTrue)\n",
    "\n",
    "    optimizerGen.apply_gradients(zip(gradsGen, generator.trainable_weights)) \n",
    "\n",
    "\n",
    "    return lossGen, totalLossDis\n",
    "\n",
    "@tf.function()\n",
    "def trainStepDis(trueImages):\n",
    "    input = tf.random.uniform((BATCH_SIZE, 1024))\n",
    "    with tf.GradientTape() as tapeGen, tf.GradientTape() as tapeDis:\n",
    "        fakeImages = generator(input, training=True) \n",
    "\n",
    "        discOutputFake = discriminator(fakeImages, training=True)\n",
    "        discOutputTrue = discriminator(trueImages, training=True)\n",
    "\n",
    "        lossGen = lossFnGen(tf.ones_like(discOutputFake), discOutputFake)\n",
    "\n",
    "        lossDisTrue = lossFnDis(tf.ones_like(discOutputTrue), discOutputTrue)\n",
    "        lossDisFake = lossFnDis(tf.zeros_like(discOutputFake), discOutputFake)\n",
    "        totalLossDis = lossDisTrue + lossDisFake\n",
    "\n",
    "    gradsDis = tapeDis.gradient(totalLossDis, discriminator.trainable_weights)\n",
    "\n",
    "    accuracyDis.update_state(tf.zeros_like(discOutputFake), discOutputFake)\n",
    "    accuracyDis.update_state(tf.ones_like(discOutputTrue), discOutputTrue)\n",
    "\n",
    "    optimizerDis.apply_gradients(zip(gradsDis, discriminator.trainable_weights)) \n",
    "\n",
    "    return lossGen, totalLossDis\n",
    "\n",
    "@tf.function()\n",
    "def trainStepGenDis(trueImages):\n",
    "    input = tf.random.uniform((BATCH_SIZE, 1024))\n",
    "    with tf.GradientTape() as tapeGen, tf.GradientTape() as tapeDis:\n",
    "        fakeImages = generator(input, training=True) \n",
    "\n",
    "        discOutputFake = discriminator(fakeImages, training=True)\n",
    "        discOutputTrue = discriminator(trueImages, training=True)\n",
    "\n",
    "        lossGen = lossFnGen(tf.ones_like(discOutputFake), discOutputFake)\n",
    "\n",
    "        lossDisTrue = lossFnDis(tf.ones_like(discOutputTrue), discOutputTrue)\n",
    "        lossDisFake = lossFnDis(tf.zeros_like(discOutputFake), discOutputFake)\n",
    "        totalLossDis = lossDisTrue + lossDisFake\n",
    "\n",
    "    gradsGen = tapeGen.gradient(lossGen, generator.trainable_weights)\n",
    "    gradsDis = tapeDis.gradient(totalLossDis, discriminator.trainable_weights)\n",
    "\n",
    "    accuracyDis.update_state(tf.zeros_like(discOutputFake), discOutputFake)\n",
    "    accuracyDis.update_state(tf.ones_like(discOutputTrue), discOutputTrue)\n",
    "\n",
    "    optimizerGen.apply_gradients(zip(gradsGen, generator.trainable_weights)) \n",
    "    optimizerDis.apply_gradients(zip(gradsDis, discriminator.trainable_weights)) \n",
    "\n",
    "    return lossGen, totalLossDis\n",
    "\n",
    "\n",
    "\n",
    "maxStep=len(allFiles)//BATCH_SIZE\n",
    "# Train the discriminator only every discHandicap steps\n",
    "discHandicap = 1\n",
    "\n",
    "for epoch in np.arange(startEpoch, startEpoch+epochs, 1):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, x_batch_train in enumerate(batchedDataset):\n",
    "        if epoch<Td:\n",
    "            lossGen, lossDis = trainStepDis(x_batch_train)\n",
    "        elif epoch<Td+Tg:\n",
    "            trainGen=True\n",
    "            trainDis=False\n",
    "            lossGen, lossDis = trainStepGen(x_batch_train)\n",
    "        else:\n",
    "            if step%discHandicap==0:\n",
    "                lossGen, lossDis = trainStepGenDis(x_batch_train)\n",
    "            else:\n",
    "                lossGen, lossDis = trainStepGen(x_batch_train)\n",
    "\n",
    "\n",
    "        # Log \n",
    "        if step % LOG_INTERVAL == 0:\n",
    "            accDis = accuracyDis.result().numpy()\n",
    "            template = 'Epoch {}/Step {}, Loss Generator: {:.4f}, Loss Discriminator: {:.4f}, Accuracy Dis: {:.4f}'\n",
    "            print(template.format(epoch, step, lossGen.numpy(), lossDis.numpy(),  accDis))\n",
    "            \n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('lossGen', lossGen, step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('lossDis', lossDis, step=maxStep*epoch+step)\n",
    "                tf.summary.scalar('Disc Accuracy', accuracyDis.result().numpy(), step=maxStep*epoch+step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "    maxStep=step\n",
    "\n",
    "    # Adaptive disc handicap\n",
    "    if accDis>0.95 and discHandicap<10 and epoch>=Td+Tg:\n",
    "        discHandicap += 1\n",
    "        print(\"Decrease disc training frequency to every {} steps\".format(discHandicap))\n",
    "    if accDis<0.65 and discHandicap>1 and epoch>=Td+Tg:\n",
    "        discHandicap -= 1\n",
    "        print(\"Increase disc training frequency to every {} steps\".format(discHandicap))\n",
    "\n",
    "    accuracyDis.reset_state()\n",
    "\n",
    "    print(\"Saving images\")\n",
    "    saveImages(generator, epoch)\n",
    "\n",
    "    if saveModel and epoch%10==0:\n",
    "      generator.save(os.path.join(DATA_PATH, \"generator_\"+\"epoch_{}\".format(epoch)))\n",
    "      discriminator.save(os.path.join(DATA_PATH, \"discriminator_\"+\"epoch_{}\".format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testInput = tf.random.uniform((9, 1024))\n",
    "# predictions = generator(testInput, training=False)\n",
    "\n",
    "# fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "# for i in range(predictions.shape[0]):\n",
    "#     plt.subplot(3, 3, i+1)\n",
    "#     plt.imshow(np.rint(predictions[i, :, :, :] * 127.5 + 127.5).astype(int))\n",
    "#     plt.axis('off')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8af0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.models.save_model(generator, os.path.join(DATA_PATH, \"generator\"))\n",
    "# tf.keras.models.save_model(discriminator, os.path.join(DATA_PATH, \"discriminator\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
